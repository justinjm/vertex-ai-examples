{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigQuery + Cloud Functions: how to run your queries as soon as a new Google Analytics table is available\n",
    "\n",
    "https://towardsdatascience.com/bigquery-cloud-functions-how-to-run-your-queries-as-soon-as-a-new-google-analytics-table-is-17fbb62f8aaa\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_number=!gcloud projects describe $(gcloud config get-value project) --format='value(projectNumber)'\n",
    "PROJECT_NUMBER = project_number[0]\n",
    "PROJECT_NUMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCATION = \"us-central1\"\n",
    "APP_NAME = \"bq-eventarc-queries-demo\"\n",
    "\n",
    "SVC_ACCOUNT_NAME=APP_NAME\n",
    "SVC_ACCOUNT_EMAIL=f\"{APP_NAME}@{PROJECT_ID}.iam.gserviceaccount.com\"\n",
    "\n",
    "DATASET_NAME = \"bq_eventarc_queries_demo\"\n",
    "TABLE_NAME = \"loan_201\"\n",
    "\n",
    "TOPIC_NAME = \"bq-load-events-topic\"\n",
    "\n",
    "BUCKET=APP_NAME\n",
    "\n",
    "BUCKET_NAME=f\"{PROJECT_ID}-{APP_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_SVC_ACCOUNT_EMAIL=f\"{PROJECT_NUMBER}-compute@developer.gserviceaccount.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Google Cloud Storage client\n",
    "storage_client = storage.Client(project=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_and_create_bucket(bucket_name, location):\n",
    "    try:\n",
    "        storage_client.get_bucket(bucket_name)\n",
    "        print(f\"Bucket {bucket_name} already exists.\")\n",
    "    except NotFound:\n",
    "        bucket = storage_client.create_bucket(bucket_or_name=bucket_name, location=location)\n",
    "        print(f\"Bucket {bucket_name} created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_and_create_bucket(BUCKET_NAME, LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Setup GCP - run `00_setup_env.sh`  - enable APIs, create GCS bucket \n",
    "3. Setup BQ - run `01_setup_bq.sh` - ingest sample data to GCS bucket, create target BQ dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Service account\n",
    "\n",
    "\n",
    "refs \n",
    "\n",
    "* https://cloud.google.com/bigquery/docs/access-control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud iam service-accounts create $SVC_ACCOUNT_NAME --project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grant the service account project editor permissions\n",
    "## or `roles/bigquery.jobUser` if minimal required\n",
    "!gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "  --member \"serviceAccount:{SVC_ACCOUNT_EMAIL}\" \\\n",
    "  --role \"roles/bigquery.admin\" \\\n",
    "  --condition=\"None\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create BQ scheduled query \n",
    "\n",
    "#TODO @justinjm - create scheduled query as part of setup BQ\n",
    "\n",
    "refs \n",
    "\n",
    "* https://cloud.google.com/bigquery/docs/scheduling-queries#python_1\n",
    "* https://cloud.google.com/bigquery/docs/access-control\n",
    "* https://cloud.google.com/iam/docs/manage-access-service-accounts#iam-view-access-sa-gcloud\n",
    "\n",
    "API\n",
    "\n",
    "* https://cloud.google.com/python/docs/reference/bigquerydatatransfer/latest/google.cloud.bigquery_datatransfer_v1.types.TransferConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO - add steps to manually create via ui and then update code here  to list \n",
    "# and get the transferID for later on\n",
    "# from google.cloud import bigquery_datatransfer\n",
    "\n",
    "# transfer_client = bigquery_datatransfer.DataTransferServiceClient()\n",
    "\n",
    "# # The project where the query job runs is the same as the project\n",
    "# # containing the destination dataset.\n",
    "# project_id = PROJECT_ID\n",
    "# dataset_id = DATASET_NAME\n",
    "\n",
    "# # This service account will be used to execute the scheduled queries. Omit\n",
    "# # this request parameter to run the query as the user with the credentials\n",
    "# # associated with this client.\n",
    "# service_account_name = SVC_ACCOUNT_EMAIL\n",
    "\n",
    "# # Use standard SQL syntax for the query.\n",
    "# query_string = f\"\"\"\n",
    "# SELECT * FROM `{PROJECT_ID}.{DATASET_NAME}.{TABLE_NAME}` LIMIT 10\n",
    "# \"\"\"\n",
    "\n",
    "# parent = transfer_client.common_project_path(project_id)\n",
    "\n",
    "# transfer_config = bigquery_datatransfer.TransferConfig(\n",
    "#     destination_dataset_id=dataset_id,\n",
    "#     display_name=\"bq-eventarc-driven-query-demo\",\n",
    "#     data_source_id=\"scheduled_query\",\n",
    "#     params={\n",
    "#         \"query\": query_string,\n",
    "#         \"destination_table_name_template\": \"processed_{run_date}\",\n",
    "#         \"write_disposition\": \"WRITE_TRUNCATE\",\n",
    "\n",
    "#     },\n",
    "#     # schedule=None,\n",
    "# )\n",
    "\n",
    "# transfer_config = transfer_client.create_transfer_config(\n",
    "#     bigquery_datatransfer.CreateTransferConfigRequest(\n",
    "#         parent=parent,\n",
    "#         transfer_config=transfer_config,\n",
    "#         service_account_name=service_account_name,\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# print(\"Created scheduled query '{}'\".format(transfer_config.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Query Workflow \n",
    "\n",
    "### Configure cloud logging filter \n",
    "\n",
    "\n",
    "Demo Version:\n",
    "\n",
    "```txt\n",
    "protoPayload.serviceData.jobCompletedEvent.job.jobConfiguration.load.destinationTable.datasetId=\"bq_eventarc_queries_demo\"\n",
    "protoPayload.serviceData.jobCompletedEvent.job.jobConfiguration.load.destinationTable.projectId=\"demos-vertex-ai\"\n",
    "protoPayload.methodName=\"jobservice.jobcompleted\"\n",
    "protoPayload.serviceData.jobCompletedEvent.job.jobConfiguration.load.destinationTable.tableId:\"loan_201\"\n",
    "```\n",
    "\n",
    "\n",
    "Google Analytics Version: \n",
    "\n",
    "```txt\n",
    "protoPayload.serviceData.jobCompletedEvent.job.jobConfiguration.load.destinationTable.datasetId=\"[REPLACE_WITH_YOUR_DATASET_ID]\"\n",
    "protoPayload.serviceData.jobCompletedEvent.job.jobConfiguration.load.destinationTable.projectId=\"REPLACE_WITH_YOUR_PROJECT_ID\"\n",
    "protoPayload.authenticationInfo.principalEmail=\"analytics-processing-dev@system.gserviceaccount.com\"\n",
    "protoPayload.methodName=\"jobservice.jobcompleted\"\n",
    "protoPayload.serviceData.jobCompletedEvent.job.jobConfiguration.load.destinationTable.tableId:\"ga_sessions\"\n",
    "NOT protoPayload.serviceData.jobCompletedEvent.job.jobConfiguration.load.destinationTable.tableId:\"ga_sessions_intraday\"\n",
    "```\n",
    "\n",
    "refs\n",
    "\n",
    "* https://cloud.google.com/logging/docs/view/building-queries\n",
    "* https://cloud.google.com/logging/docs/view/logging-query-language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Pub/Sub topic\n",
    "!gcloud pubsub topics create $TOPIC_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create log sink filter based on query above \n",
    "!gcloud logging sinks create bq-load-events-sink \"pubsub.googleapis.com/projects/${PROJECT_ID}/topics/${TOPIC_NAME}\" \\\n",
    "    --log-filter='protoPayload.serviceData.jobCompletedEvent.job.jobConfiguration.load.destinationTable.datasetId=\\\"bq_eventarc_queries_demo\\\" AND protoPayload.serviceData.jobCompletedEvent.job.jobConfiguration.load.destinationTable.projectId=\\\"demos-vertex-ai\\\" AND protoPayload.methodName=\\\"jobservice.jobcompleted\\\" AND protoPayload.serviceData.jobCompletedEvent.job.jobConfiguration.load.destinationTable.tableId:\\\"loan_201\\\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grant `serviceAccount:service-PROJECT_NUMBER@gcp-sa-logging.iam.gserviceaccount.com` the Pub/Sub Publisher role on the topic.\n",
    "# More information about sinks can be found at https://cloud.google.com/logging/docs/export/configure_export\n",
    "!gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "  --member=\"serviceAccount:service-${PROJECT_NUMBER}@gcp-sa-logging.iam.gserviceaccount.com\" \\\n",
    "  --role=\"roles/pubsub.publisher\" \\\n",
    "  --project=$PROJECT_ID \\\n",
    "  --condition=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Cloud Function \n",
    "\n",
    "\n",
    "Create and deploy a Cloud function from the source code in the [functions](functions/) directory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CF files \n",
    "\n",
    "First we create necessary files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm -rf functions/\n",
    "!mkdir functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile functions/main.py \n",
    "import time\n",
    "from google.protobuf.timestamp_pb2 import Timestamp\n",
    "from google.cloud import bigquery_datatransfer_v1\n",
    "\n",
    "def runQuery (parent, requested_run_time):\n",
    "    client = bigquery_datatransfer_v1.DataTransferServiceClient()\n",
    "    projectid = '746038361521' # Enter your projectID here\n",
    "    transferid = '670dbb89-0000-27e1-9de1-883d24f77884'  # Enter your transferId here\n",
    "    parent = client.project_transfer_config_path(projectid, transferid)\n",
    "    start_time = bigquery_datatransfer_v1.types.Timestamp(seconds=int(time.time() + 10))\n",
    "    response = client.start_manual_transfer_runs(parent, requested_run_time=start_time)\n",
    "    print(response)\n",
    "    \n",
    "# do not forget to put google-cloud-bigquery-datatransfer==1 in the requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile functions/requirements.txt\n",
    "google-cloud-bigquery-datatransfer==1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Cloud Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud functions deploy bq-eventarc-driven-queries-demo \\\n",
    "  --gen2 \\\n",
    "  --region=us-central1 \\\n",
    "  --runtime=python311 \\\n",
    "  --source=functions/ \\\n",
    "  --entry-point=runQuery \\\n",
    "  --trigger-topic=$TOPIC_NAME \\\n",
    "  --timeout=540 \\\n",
    "  --no-allow-unauthenticated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test\n",
    "\n",
    "By creating a new table in BQ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "!DATA_FILE_CSV=\"loan_201.csv\"\n",
    "# copied from above to match args file\n",
    "!BQ_DATASET=\"bq_eventarc_queries_demo\"\n",
    "!BQ_TABLE_DATA=\"loan_201\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create table - target table\n",
    "!bq load \\\n",
    "    --autodetect=TRUE \\\n",
    "    --skip_leading_rows=1 \\\n",
    "    bq_eventarc_queries_demo.loan_201 \\\n",
    "    gs://demos-vertex-ai-bq-eventarc-driven-queries/$DATA_FILE_CSV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
