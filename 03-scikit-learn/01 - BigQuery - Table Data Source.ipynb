{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c28f7fa2",
   "metadata": {},
   "source": [
    "# 01 - BigQuery - Table Data Source\n",
    "Use BigQuery to load and prepare data for machine learning:\n",
    "\n",
    "**Video Walkthrough of this notebook:**\n",
    "\n",
    "Includes conversational walkthrough and more explanatory information than the notebook:\n",
    "<p align=\"center\" width=\"100%\"><center><a href=\"https://youtu.be/Z5whg20WvS8\" target=\"_blank\" rel=\"noopener noreferrer\"><img src=\"../architectures/thumbnails/playbutton/01.png\" width=\"40%\"></a></center></p>\n",
    "\n",
    "**Prerequisites:**\n",
    "-  [00 - Environment Setup](../00%20-%20Setup/00%20-%20Environment%20Setup.ipynb)\n",
    "\n",
    "**Resources:**\n",
    "-  [Python Client For Google BigQuery](https://googleapis.dev/python/bigquery/latest/index.html)\n",
    "-  [Download BigQuery Data to Pandas](https://cloud.google.com/bigquery/docs/bigquery-storage-python-pandas)\n",
    "-  [BigQuery Template Notebooks](https://github.com/GoogleCloudPlatform/bigquery-notebooks/tree/main/notebooks/official/template_notebooks)\n",
    "- Using BigQuery From Python, Notebooks in This Repository:\n",
    "    - [Tips/BigQuery - Python Client](../Tips/BigQuery%20-%20Python%20Client.ipynb)\n",
    "    - [03 - BigQuery ML (BQML)/Introduction to BigQuery ML (BQML)](../03%20-%20BigQuery%20ML%20(BQML)/Introduction%20to%20BigQuery%20ML%20(BQML).ipynb)\n",
    "    - [Applied Forecasting/1 - BigQuery Time Series Forecasting Data Review and Preparation](../Applied%20Forecasting/1%20-%20BigQuery%20Time%20Series%20Forecasting%20Data%20Review%20and%20Preparation.ipynb)\n",
    "\n",
    "**Conceptual Flow & Workflow**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img alt=\"Conceptual Flow\" src=\"../architectures/slides/01_arch.png\" width=\"45%\">\n",
    "&nbsp; &nbsp; &nbsp; &nbsp;\n",
    "  <img alt=\"Workflow\" src=\"../architectures/slides/01_console.png\" width=\"45%\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0c695d-002d-48ca-9d52-839f95fdfee0",
   "metadata": {},
   "source": [
    "---\n",
    "## Source Data\n",
    "\n",
    "**Overview**\n",
    "\n",
    "This notebook imports source data for this project into Google BigQuery.  All the remaining notebooks utilize BigQuery as the source and leverage API's native to the machine learning approaches they feature.\n",
    "\n",
    "In the enviornment setup notebook (00), a BigQuery source table was exported to CSV format in a Cloud Storage Bucket. This notebook, `01 - BigQuery - Table Data Source`, starts the machine learning lifecycle by importing source data and preparing it for machine learning.\n",
    "\n",
    "All of these workflows utilize tabular data to fit a supervised learning model: predict a target variable by learning patterns in feature columns.  The type of supervised learning used in these projects is classification: models with a target variable that has multiple discrete classes.  \n",
    "\n",
    "**The Data**\n",
    "\n",
    "The source data is first exported to Google Cloud Storage in CSV format below.  The BigQuery source table is `bigquery-public-data.ml_datasets.ulb_fraud_detection`.  This is a table of credit card transactions that are classified as fradulant, `Class = 1`, or normal `Class = 0`.    \n",
    "- The data can be researched further at this [Kaggle link](https://www.kaggle.com/mlg-ulb/creditcardfraud).\n",
    "- Read mode about BigQuery public datasets [here](https://cloud.google.com/bigquery/public-data)\n",
    "\n",
    "**Description of the Data**\n",
    "\n",
    "This is a table of 284,807 credit card transactions classified as fradulant or normal in the column `Class`.  In order protect confidentiality, the original features have been transformed using [principle component analysis (PCA)](https://en.wikipedia.org/wiki/Principal_component_analysis) into 28 features named `V1, V2, ... V28` (float).  Two descriptive features are provided without transformation by PCA:\n",
    "- `Time` (integer) is the seconds elapsed between the transaction and the earliest transaction in the table\n",
    "- `Amount` (float) is the value of the transaction\n",
    ">**Quick Note on PCA**<p>PCA is an unsupervised learning technique: there is not a target variable.  PCA is commonlly used as a variable/feature reduction technique.  If you have 100 features then you could reduce it to a number p (say 10) projected features.  The choice of this number is a balance of how well it can explain the variance of the full feature space and reducing the number of features.  Each projected feature is orthogonal to each other feature, meaning there is no correlation between these new projected features.</p>\n",
    "\n",
    "**Preparation of the Data**\n",
    "\n",
    "This notebook adds two columns to the source data and stores it in a new table with suffix `_prepped`.  \n",
    "- `transaction_id` (string) a unique id for the row/transaction\n",
    "- `splits` (string) this divided the tranactions into sets for `TRAIN` (80%), `VALIDATE` (10%), and `TEST` (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5046940",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ae60b2",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f0503a-e864-4170-ade9-0ebabd14efcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56a5bc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "EXPERIMENT = '01'\n",
    "SERIES = '01'\n",
    "\n",
    "# source data\n",
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = 'fraud'\n",
    "BQ_TABLE = 'fraud'\n",
    "\n",
    "# Data source for this series of notebooks: Described above\n",
    "BQ_SOURCE = 'bigquery-public-data.ml_datasets.ulb_fraud_detection'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a963be",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a37b83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24cebb6",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e515410",
   "metadata": {},
   "outputs": [],
   "source": [
    "bq = bigquery.Client(project = PROJECT_ID)\n",
    "gcs = storage.Client(project = PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6601398",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f1e2af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUCKET = PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504c3a89-d98f-471c-ae54-3b9157651f0b",
   "metadata": {},
   "source": [
    "---\n",
    "## Store the Source Data in GCS Storage Bucket\n",
    "Check to see if the export exist and create if not:\n",
    "- export from bigquery table to GCS bucket as CSV\n",
    "    - the table is referenced in the `BQ_SOURCE` variable at the top of this notebook\n",
    "- [Exporting Table Data](https://cloud.google.com/bigquery/docs/exporting-data#python)\n",
    "- [BigQuery Python Client](https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.client.Client#google_cloud_bigquery_client_Client_extract_table)\n",
    "\n",
    "For more tips on interacting with GCS using the Python Client review the tips notebook [Python Client for GCS](../Tips/Python%20Client%20for%20GCS.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6144857f-1ecc-4712-925b-4de69b6df0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = f\"{SERIES}/{EXPERIMENT}/data/{BQ_TABLE}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65714181-b946-4c5c-b990-6f7ac4f2ca2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketDef = gcs.bucket(BUCKET)\n",
    "if storage.Blob(bucket = bucketDef, name = file).exists(gcs):\n",
    "    print(f'The file has already been created at: gs://{bucketDef.name}/{file}')\n",
    "else:\n",
    "    source = bigquery.TableReference.from_string(BQ_SOURCE)\n",
    "    extract = bq.extract_table(source = source, destination_uris = [f'gs://{bucketDef.name}/{file}'])\n",
    "    print('Creating the export ...')\n",
    "    extract.result()\n",
    "    print(f'Exported the table to: gs://{bucketDef.name}/{file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648c19f8-677e-4219-a0ff-bcfe1fd932a0",
   "metadata": {},
   "source": [
    "list files in the bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed784872-405b-4d64-a70b-4482529b5fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(bucketDef.list_blobs(prefix = f'{SERIES}/{EXPERIMENT}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40c2ea7-0649-4073-88a4-3e47af62f0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Review the files in the console here:\\nhttps://console.cloud.google.com/storage/browser/{PROJECT_ID}/{SERIES};tab=objects&project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7685eddc",
   "metadata": {},
   "source": [
    "---\n",
    "## Create BigQuery Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77cab37",
   "metadata": {},
   "source": [
    "List BigQuery datasets in the project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b49b948-5fa8-4d4e-a7d3-b2adb19362c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = list(bq.list_datasets())\n",
    "for d in datasets:\n",
    "    print(d.dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0b3aca",
   "metadata": {},
   "source": [
    "Create the dataset if missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61001b78-418f-42a1-a4c4-d74a1f3aff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = bigquery.Dataset(f\"{BQ_PROJECT}.{BQ_DATASET}\")\n",
    "ds.location = REGION\n",
    "ds.labels = {'experiment': f'{EXPERIMENT}'}\n",
    "ds = bq.create_dataset(dataset = ds, exists_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a50638-515e-49d0-b479-25e92138ae96",
   "metadata": {},
   "source": [
    "List BigQuery datasets in the project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39f4471-38f4-4b97-8d9c-7ee3122dbee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = list(bq.list_datasets())\n",
    "for d in datasets:\n",
    "    print(d.dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34eeac68",
   "metadata": {},
   "source": [
    "---\n",
    "## Create BigQuery Table\n",
    "- import data from Cloud Storage Bucket\n",
    "- [Loading CSV data from Cloud Storage](https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-csv)\n",
    "- [BigQuery Python Client](https://cloud.google.com/python/docs/reference/bigquery/latest/google.cloud.bigquery.client.Client#google_cloud_bigquery_client_Client_extract_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86063a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud.exceptions import NotFound\n",
    "try:\n",
    "    table = bq.get_table(f'{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}')\n",
    "    if table:\n",
    "        print(f'The table already exists: {BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}')\n",
    "except NotFound as error:\n",
    "    print(f'Creating Table ...')\n",
    "    destination = bigquery.TableReference.from_string(f\"{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}\")\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        write_disposition = 'WRITE_TRUNCATE',\n",
    "        source_format = bigquery.SourceFormat.CSV,\n",
    "        autodetect = True,\n",
    "        labels = {'experiment': f'{EXPERIMENT}'}\n",
    "    )\n",
    "    job = bq.load_table_from_uri(f\"gs://{bucketDef.name}/{file}\", destination, job_config = job_config)\n",
    "    job.result()\n",
    "    print(f'Finished creating table: {BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44285e37-6ac7-478d-9709-dd11a068a4dc",
   "metadata": {},
   "source": [
    "### Retrieve and Review a Sample From The Table:\n",
    "> **Note:** The `LIMIT 5` statement does limit the number of rows returned by BigQuery to 5 but BigQuery still does a full table scan.  If you have a table larger than 1GB and want to limit the rows scanned for a quick review like then then replacing `LIMIT 5` with `TABLESAMPLE SYSTEM (1 PERCENT)` would be more efficient.  For tables under 1GB it will still return the full table.  More on [Table Sampling](https://cloud.google.com/bigquery/docs/table-sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11924cf8-a040-4ee5-85ae-788cba106b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT *\n",
    "FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}` TABLESAMPLE SYSTEM (1 PERCENT)\n",
    "#LIMIT 5\n",
    "\"\"\"\n",
    "bq.query(query = query).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85ccdce-e6a9-4735-9997-e5ae77a6f86c",
   "metadata": {},
   "source": [
    "### Check out this table in BigQuery Console:\n",
    "- Click: https://console.cloud.google.com/bigquery\n",
    "- Make sure project selected is the one from this notebook\n",
    "- Under Explore, expand this project and review the dataset and table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d439a1dc-dfdd-4c82-8302-8dc1ffe44d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Direct Link To This Project In BigQuery:\\nhttps://console.cloud.google.com/bigquery?project={PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f133efb-8232-4b21-814f-23b815dc60f2",
   "metadata": {},
   "source": [
    "---\n",
    "## Review Data in BigQuery\n",
    "Additional SQL queries could be used to review the data.  This section shows moving the table to a Pandas dataframe for local review in Python:\n",
    "\n",
    "> **Note:** <p>This query only selects one column.  This means BigQuery scans less data as it does not process the other columns.  </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4ebf6f5-a178-4011-9ab6-fa8329c578c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT Class\n",
    "FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}`\n",
    "\"\"\"\n",
    "df = bq.query(query = query).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674f716e-8b9d-4c92-9b46-c166b869f6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5d17e5-07c3-48fd-b682-aa471f3548f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b34894",
   "metadata": {},
   "source": [
    "---\n",
    "## Prepare Data for Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c982157",
   "metadata": {},
   "source": [
    "Create a prepped version of the data with test/train splits using SQL DDL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50becbb-60ab-45f9-acd5-9beb5b6755f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}_prepped` AS\n",
    "WITH add_id AS(SELECT *, GENERATE_UUID() transaction_id FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}`)\n",
    "SELECT *,\n",
    "    CASE \n",
    "        WHEN MOD(ABS(FARM_FINGERPRINT(transaction_id)),10) < 8 THEN \"TRAIN\" \n",
    "        WHEN MOD(ABS(FARM_FINGERPRINT(transaction_id)),10) < 9 THEN \"VALIDATE\"\n",
    "        ELSE \"TEST\"\n",
    "    END AS splits\n",
    "FROM add_id\n",
    "\"\"\"\n",
    "job = bq.query(query = query)\n",
    "job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d6e2a9-ec35-477c-9d50-429326acc41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(job.ended-job.started).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a991ff73-a545-4eed-a709-b8292efd89ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if job.estimated_bytes_processed:\n",
    "    print(f'{job.estimated_bytes_processed/1000000} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372b2c41",
   "metadata": {},
   "source": [
    "Review the test/train split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a94adb9-81d7-4710-ac50-e0d93dd5523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT splits, count(*) as Count, 100*count(*) / (sum(count(*)) OVER()) as Percentage\n",
    "FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}_prepped`\n",
    "GROUP BY splits\n",
    "\"\"\"\n",
    "bq.query(query = query).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3006ed11",
   "metadata": {},
   "source": [
    "Retrieve a subset of the data to a Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ea70141-07db-46b0-a31e-0968befcd37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "SELECT * \n",
    "FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}_prepped`\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "data = bq.query(query = query).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326d2b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d575d1",
   "metadata": {},
   "source": [
    "---\n",
    "## Remove Resources\n",
    "see notebook \"99 - Cleanup\""
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-11.m104",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-11:m104"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
