{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03f - Vertex AI > Training > Training Pipelines - With Custom Container\n",
    "\n",
    "**03 Series Overview**\n",
    "\n",
    "Where a model gets trained is where it consumes computing resources.  With Vertex AI, you have choices for configuring the computing resources available at training.  This notebook is an example of an execution environment.  When it was set up there were choices for machine type and accelerators (GPUs).  \n",
    "\n",
    "In the [03 - Vertex AI Custom Model - scikit-learn - in Notebook](./03%20-%20Vertex%20AI%20Custom%20Model%20-%20scikit-learn%20-%20in%20Notebook.ipynb) notebook, the model training happened directly in the notebook.  The model was then imported to Vertex AI and deployed to an endpoint for online predictions. \n",
    "\n",
    "In this `03a-03i` series of demonstrations, the same model is trained using managed computing resources in Vertex AI Training as managed jobs.  These jobs will be demonstrated as:\n",
    "\n",
    "-  Custom Job that trains and saves (to GCS) a model from a python script (`03a`), python source distribution (`03b`), and custom container (`03c`)\n",
    "-  Training Pipeline that trains and registers a model from a python script (`03d`), python source distribution (`03e`), and custom container (`03f`)\n",
    "-  Hyperparameter Tuning Jobs from a python script (`03g`), python source distribution (`03h`), and custom container (`03i`)\n",
    "\n",
    "**This Notebook (`03f`): An extension of `03c` as a Training Pipeline that saves the model to Vertex AI > Model Registry**\n",
    "\n",
    "This notebook trains the same scikit-learn logistic regression model from [03 - Vertex AI Custom Model - scikit-learn - in Notebook](./03%20-%20Vertex%20AI%20Custom%20Model%20-%20scikit-learn%20-%20in%20Notebook.ipynb) by first modifying and saving the training code to a Python script as shown in [03 - Vertex AI Custom Model - scikit-learn - Notebook to Script](./03%20-%20Vertex%20AI%20Custom%20Model%20-%20scikit-learn%20-%20Notebook%20to%20Script.ipynb). \n",
    "\n",
    "A custom container is built that contains the script and required Python libaries.  For more guidance on this process visit the tip notebook [Python Custom Containers](../Tips/Python%20Custom%20Containers.ipynb).  The script, along with a `requirement.txt` and `Dockerfile` are stored in GCS and then used by Cloud Build to extend the pre-built Vertex AI container and store the resulting image in Artifact Registry.  \n",
    "\n",
    "Compared to the Custom Job in `03c` the primary considerations for this Training Pipeline are:\n",
    "- the final model is registered to Vertex AI > Model Registry\n",
    "- the training pipeline triggers a similar custom job in Vertex AI > Training\n",
    "\n",
    "This job is launched using the Vertex AI client library:\n",
    "- [Python Cloud Client Libraries](https://cloud.google.com/python/docs/reference)\n",
    "    - [google-cloud-aiplatform](https://cloud.google.com/python/docs/reference/aiplatform/latest)\n",
    "        - [`aiplatform` package](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform)\n",
    "            - [`aiplatform.CustomContainerTrainingJob()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomContainerTrainingJob#google_cloud_aiplatform_CustomContainerTrainingJob)\n",
    "            - and run with the method [`.run()`](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform.CustomContainerTrainingJob#google_cloud_aiplatform_CustomContainerTrainingJob_run)\n",
    "\n",
    "**Vertex AI Training**\n",
    "\n",
    "In Vertex AI Training you can run your training code as a job where you specify the compute resources to use. For tips on preparing code, running training jobs, and workflows for building custom containers with software and training code combined please visit these [tips notebooks](../Tips/readme.md) in this repository:\n",
    "- [Python Packages](../Tips/Python%20Packages.ipynb)\n",
    "- [Python Custom Containers](../Tips/Python%20Custom%20Containers.ipynb)\n",
    "- [Python Training](../Tips/Python%20Training.ipynb)\n",
    "\n",
    "<p align=\"center\" width=\"100%\">\n",
    "    <img src=\"../architectures/overview/training.png\" width=\"45%\">\n",
    "    &nbsp; &nbsp; &nbsp; &nbsp;\n",
    "    <img src=\"../architectures/overview/training2.png\" width=\"45%\">\n",
    "</p>\n",
    "\n",
    "**Prerequisites:**\n",
    "-  [01 - BigQuery - Table Data Source](../01%20-%20Data%20Sources/01%20-%20BigQuery%20-%20Table%20Data%20Source.ipynb)\n",
    "-  Understanding:\n",
    "    -  Model overview in [03 - Vertex AI Custom Model - scikit-learn - in Notebook](./03%20-%20Vertex%20AI%20Custom%20Model%20-%20scikit-learn%20-%20in%20Notebook.ipynb)\n",
    "    -  Convert notebook code to Python Script in [03 - Vertex AI Custom Model - scikit-learn - Notebook to Script](./03%20-%20Vertex%20AI%20Custom%20Model%20-%20scikit-learn%20-%20Notebook%20to%20Script.ipynb)\n",
    "\n",
    "**Resources:**\n",
    "- [Vertex AI Custom Container For Training](https://cloud.google.com/vertex-ai/docs/training/containers-overview)\n",
    "\n",
    "**Conceptual Flow & Workflow**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img alt=\"Conceptual Flow\" src=\"../architectures/slides/05f_arch.png\" width=\"45%\">\n",
    "&nbsp; &nbsp; &nbsp; &nbsp;\n",
    "  <img alt=\"Workflow\" src=\"../architectures/slides/05f_console.png\" width=\"45%\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Installs (if needed)\n",
    "\n",
    "This notebook uses the Python Clients for\n",
    "- Google Service Usage\n",
    "    - to enable APIs (Artifact Registry and Cloud Build)\n",
    "- Artifact Registry\n",
    "    - to create repositories for Python packages and Docker containers\n",
    "- Cloud Build\n",
    "    - To build custom Docker containers\n",
    "\n",
    "The cells below check to see if the required Python libraries are installed.  If any are not it will print a message to do the install with the associated pip command to use.  These installs must be completed before continuing this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.cloud.service_usage_v1\n",
    "except ImportError:\n",
    "    print('You need to pip install google-cloud-service-usage')\n",
    "    !pip install google-cloud-service-usage -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.cloud.artifactregistry_v1\n",
    "except ImportError:\n",
    "    print('You need to pip install google-cloud-artifact-registry')\n",
    "    !pip install google-cloud-artifact-registry -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.cloud.devtools.cloudbuild\n",
    "except ImportError:\n",
    "    print('You need to pip install google-cloud-build')\n",
    "    !pip install google-cloud-build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'demos-vertex-ai'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "EXPERIMENT = '03f'\n",
    "SERIES = '03'\n",
    "\n",
    "# source data\n",
    "BQ_PROJECT = PROJECT_ID\n",
    "BQ_DATASET = 'fraud'\n",
    "BQ_TABLE = 'fraud_prepped'\n",
    "\n",
    "# Resources\n",
    "## https://cloud.google.com/deep-learning-containers/docs/choosing-container\n",
    "# https://cloud.google.com/vertex-ai/docs/training/create-custom-container\n",
    "BASE_IMAGE = 'us-docker.pkg.dev/deeplearning-platform-release/gcr.io/sklearn-cpu.0-23'\n",
    "DEPLOY_IMAGE = 'us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-5:latest' # https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers#expandable-4\n",
    "TRAIN_IMAGE = 'us-docker.pkg.dev/vertex-ai/training/sklearn-cpu.1-0:latest' # https://cloud.google.com/vertex-ai/docs/training/pre-built-containers#scikit-learn\n",
    "\n",
    "TRAIN_COMPUTE = 'n1-standard-4'\n",
    "DEPLOY_COMPUTE = 'n1-standard-4'\n",
    "\n",
    "# Model Training\n",
    "VAR_TARGET = 'Class'\n",
    "VAR_OMIT = 'transaction_id-splits' + '-' + VAR_TARGET # add more variables to the string with space delimiters\n",
    "SOLVER = 'newton-cg'\n",
    "PENALTY = 'l2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "from datetime import datetime\n",
    "import pkg_resources\n",
    "from IPython.display import Markdown as md\n",
    "from google.cloud import service_usage_v1\n",
    "from google.cloud.devtools import cloudbuild_v1\n",
    "from google.cloud import artifactregistry_v1\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "bq = bigquery.Client(project=PROJECT_ID)\n",
    "gcs = storage.Client(project=PROJECT_ID)\n",
    "su_client = service_usage_v1.ServiceUsageClient()\n",
    "ar_client = artifactregistry_v1.ArtifactRegistryClient()\n",
    "cb_client = cloudbuild_v1.CloudBuildClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "BUCKET = PROJECT_ID\n",
    "URI = f\"gs://{BUCKET}/{SERIES}/{EXPERIMENT}\"\n",
    "DIR = f\"temp/{EXPERIMENT}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'746038361521-compute@developer.gserviceaccount.com'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SERVICE_ACCOUNT = !gcloud config list --format='value(core.account)' \n",
    "SERVICE_ACCOUNT = SERVICE_ACCOUNT[0]\n",
    "SERVICE_ACCOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the service accounts current roles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROLE\n",
      "roles/aiplatform.admin\n",
      "roles/aiplatform.customCodeServiceAgent\n",
      "roles/aiplatform.user\n",
      "roles/bigquery.admin\n",
      "roles/editor\n",
      "roles/iam.serviceAccountAdmin\n",
      "roles/notebooks.serviceAgent\n",
      "roles/storage.admin\n",
      "roles/storage.objectAdmin\n"
     ]
    }
   ],
   "source": [
    "!gcloud projects get-iam-policy $PROJECT_ID --filter=\"bindings.members:$SERVICE_ACCOUNT\" --format='table(bindings.role)' --flatten=\"bindings[].members\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Note: If the resulting list is missing [roles/storage.objectAdmin](https://cloud.google.com/storage/docs/access-control/iam-roles) then [revisit the setup notebook](../00%20-%20Setup/00%20-%20Environment%20Setup.ipynb#permissions) and add this permission to the service account with the provided instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf {DIR}\n",
    "!mkdir -p {DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment Tracking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAMEWORK = 'sklearn'\n",
    "TASK = 'classification'\n",
    "MODEL_TYPE = 'logistric-regression'\n",
    "EXPERIMENT_NAME = f'experiment-{SERIES}-{EXPERIMENT}-{FRAMEWORK}-{TASK}-{MODEL_TYPE}'\n",
    "RUN_NAME = f'run-{TIMESTAMP}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Enable APIs\n",
    "\n",
    "Using Cloud Build and Artifact Registry requires enabling these APIs for the Google Cloud Project.\n",
    "\n",
    "Options for enabeling these.  In this notebook option 2 is used.\n",
    " 1. Use the APIs & Services page in the console: https://console.cloud.google.com/apis\n",
    "     - `+ Enable APIs and Services`\n",
    "     - Search for Cloud Build and Enable\n",
    "     - Search for Artifact Registry and Enable\n",
    " 2. Use [Google Service Usage](https://cloud.google.com/service-usage/docs) API from Python\n",
    "     - [Python Client For Service Usage](https://github.com/googleapis/python-service-usage)\n",
    "     - [Python Client Library Documentation](https://cloud.google.com/python/docs/reference/serviceusage/latest)\n",
    "     \n",
    "The following code cells use the Service Usage Client to:\n",
    "- get the state of the service\n",
    "- if 'DISABLED':\n",
    "    - Try enabling the service and return the state after trying\n",
    "- if 'ENABLED' print the state for confirmation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Artifact Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifact Registry already enabled for project: demos-vertex-ai\n"
     ]
    }
   ],
   "source": [
    "artifactregistry = su_client.get_service(\n",
    "    request = service_usage_v1.GetServiceRequest(\n",
    "        name = f'projects/{PROJECT_ID}/services/artifactregistry.googleapis.com'\n",
    "    )\n",
    ").state.name\n",
    "\n",
    "\n",
    "if artifactregistry == 'DISABLED':\n",
    "    print(f'Artifact Registry is currently {artifactregistry} for project: {PROJECT_ID}')\n",
    "    print(f'Trying to Enable...')\n",
    "    operation = su_client.enable_service(\n",
    "        request = service_usage_v1.EnableServiceRequest(\n",
    "            name = f'projects/{PROJECT_ID}/services/artifactregistry.googleapis.com'\n",
    "        )\n",
    "    )\n",
    "    response = operation.result()\n",
    "    if response.service.state.name == 'ENABLED':\n",
    "        print(f'Artifact Registry is now enabled for project: {PROJECT_ID}')\n",
    "    else:\n",
    "        print(response)\n",
    "else:\n",
    "    print(f'Artifact Registry already enabled for project: {PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cloud Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloud Build already enabled for project: demos-vertex-ai\n"
     ]
    }
   ],
   "source": [
    "cloudbuild = su_client.get_service(\n",
    "    request = service_usage_v1.GetServiceRequest(\n",
    "        name = f'projects/{PROJECT_ID}/services/cloudbuild.googleapis.com'\n",
    "    )\n",
    ").state.name\n",
    "\n",
    "\n",
    "if cloudbuild == 'DISABLED':\n",
    "    print(f'Cloud Build is currently {cloudbuild} for project: {PROJECT_ID}')\n",
    "    print(f'Trying to Enable...')\n",
    "    operation = su_client.enable_service(\n",
    "        request = service_usage_v1.EnableServiceRequest(\n",
    "            name = f'projects/{PROJECT_ID}/services/cloudbuild.googleapis.com'\n",
    "        )\n",
    "    )\n",
    "    response = operation.result()\n",
    "    if response.service.state.name == 'ENABLED':\n",
    "        print(f'Cloud Build is now enabled for project: {PROJECT_ID}')\n",
    "    else:\n",
    "        print(response)\n",
    "else:\n",
    "    print(f'Cloud Build already enabled for project: {PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup Vertex AI Experiments\n",
    "\n",
    "The code in this section initializes the experiment and starts a run that represents this notebook.  Throughout the notebook sections for model training and evaluation information will be logged to the experiment using:\n",
    "- [.log_params](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_log_params)\n",
    "- [.log_metrics](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_log_metrics)\n",
    "- [.log_time_series_metrics](https://cloud.google.com/python/docs/reference/aiplatform/latest/google.cloud.aiplatform#google_cloud_aiplatform_log_time_series_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        \n",
       "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
       "    <style>\n",
       "      .view-vertex-resource,\n",
       "      .view-vertex-resource:hover,\n",
       "      .view-vertex-resource:visited {\n",
       "        position: relative;\n",
       "        display: inline-flex;\n",
       "        flex-direction: row;\n",
       "        height: 32px;\n",
       "        padding: 0 12px;\n",
       "          margin: 4px 18px;\n",
       "        gap: 4px;\n",
       "        border-radius: 4px;\n",
       "\n",
       "        align-items: center;\n",
       "        justify-content: center;\n",
       "        background-color: rgb(255, 255, 255);\n",
       "        color: rgb(51, 103, 214);\n",
       "\n",
       "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
       "        font-size: 13px;\n",
       "        font-weight: 500;\n",
       "        text-transform: uppercase;\n",
       "        text-decoration: none !important;\n",
       "\n",
       "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
       "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active {\n",
       "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
       "      }\n",
       "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
       "        position: absolute;\n",
       "        top: 0;\n",
       "        bottom: 0;\n",
       "        left: 0;\n",
       "        right: 0;\n",
       "        border-radius: 4px;\n",
       "        pointer-events: none;\n",
       "\n",
       "        content: '';\n",
       "        background-color: rgb(51, 103, 214);\n",
       "        opacity: 0.12;\n",
       "      }\n",
       "      .view-vertex-icon {\n",
       "        font-size: 18px;\n",
       "      }\n",
       "    </style>\n",
       "  \n",
       "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-832da30d-9840-47a9-85e4-e4faa3d6982f\" href=\"#view-view-vertex-resource-832da30d-9840-47a9-85e4-e4faa3d6982f\">\n",
       "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
       "          <span>View Experiment</span>\n",
       "        </a>\n",
       "        \n",
       "        <script>\n",
       "          (function () {\n",
       "            const link = document.getElementById('view-vertex-resource-832da30d-9840-47a9-85e4-e4faa3d6982f');\n",
       "            link.addEventListener('click', (e) => {\n",
       "              if (window.google?.colab?.openUrl) {\n",
       "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/experiment-03-03f-sklearn-classification-logistric-regression/runs?project=demos-vertex-ai');\n",
       "              } else {\n",
       "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/experiment-03-03f-sklearn-classification-logistric-regression/runs?project=demos-vertex-ai', '_blank');\n",
       "              }\n",
       "              e.stopPropagation();\n",
       "              e.preventDefault();\n",
       "            });\n",
       "          })();\n",
       "        </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aiplatform.init(experiment = EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python File for Training\n",
    "\n",
    "This notebook trains the same scikit-learn Keras model from [03 - Vertex AI Custom Model - scikit-learn - in Notebook](./03%20-%20Vertex%20AI%20Custom%20Model%20-%20scikit-learn%20-%20in%20Notebook.ipynb) by first modifying and saving the training code to a python script as shown in [03 - Vertex AI Custom Model - scikit-learn - Notebook to Script](./03%20-%20Vertex%20AI%20Custom%20Model%20-%20scikit-learn%20-%20Notebook%20to%20Script.ipynb) which stores the script in [`./code/train.py`](./code/train.py).\n",
    "\n",
    "**Review the script:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "\n",
       "\n",
       "# package import\n",
       "import sklearn\n",
       "from sklearn.preprocessing import StandardScaler\n",
       "from sklearn.linear_model import LogisticRegression\n",
       "from sklearn.pipeline import Pipeline\n",
       "from sklearn import metrics\n",
       "\n",
       "import pickle\n",
       "import pandas as pd \n",
       "import numpy as np \n",
       "\n",
       "from google.cloud import bigquery\n",
       "from google.cloud import aiplatform\n",
       "from google.cloud import storage\n",
       "import argparse\n",
       "import os\n",
       "import sys\n",
       "\n",
       "# import argument to local variables\n",
       "parser = argparse.ArgumentParser()\n",
       "# the passed param, dest: a name for the param, default: if absent fetch this param from the OS, type: type to convert to, help: description of argument\n",
       "parser.add_argument('--penalty', dest = 'penalty', default = 'l2', type = str, help = 'Penalty term')\n",
       "parser.add_argument('--solver', dest = 'solver', default = 'newton-cg', type = str, help = 'Logistic regression solver')\n",
       "parser.add_argument('--var_target', dest = 'var_target', type=str)\n",
       "parser.add_argument('--var_omit', dest = 'var_omit', type=str)\n",
       "parser.add_argument('--project_id', dest = 'project_id', type=str)\n",
       "parser.add_argument('--bq_project', dest = 'bq_project', type=str)\n",
       "parser.add_argument('--bq_dataset', dest = 'bq_dataset', type=str)\n",
       "parser.add_argument('--bq_table', dest = 'bq_table', type=str)\n",
       "parser.add_argument('--region', dest = 'region', type=str)\n",
       "parser.add_argument('--experiment', dest = 'experiment', type=str)\n",
       "parser.add_argument('--series', dest = 'series', type=str)\n",
       "parser.add_argument('--experiment_name', dest = 'experiment_name', type=str)\n",
       "parser.add_argument('--run_name', dest = 'run_name', type=str)\n",
       "args = parser.parse_args()\n",
       "\n",
       "# Model Training\n",
       "VAR_TARGET = str(args.var_target)\n",
       "VAR_OMIT = str(args.var_omit).split('-')\n",
       "\n",
       "# clients\n",
       "bq = bigquery.Client(project = args.project_id)\n",
       "aiplatform.init(project = args.project_id, location = args.region)\n",
       "\n",
       "# Vertex AI Experiment\n",
       "if args.run_name in [run.name for run in aiplatform.ExperimentRun.list(experiment = args.experiment_name)]:\n",
       "    expRun = aiplatform.ExperimentRun(run_name = args.run_name, experiment = args.experiment_name)\n",
       "else:\n",
       "    expRun = aiplatform.ExperimentRun.create(run_name = args.run_name, experiment = args.experiment_name)\n",
       "expRun.log_params({'experiment': args.experiment, 'series': args.series, 'project_id': args.project_id})\n",
       "\n",
       "# get schema from bigquery source\n",
       "query = f\"SELECT * FROM `{args.bq_project}.{args.bq_dataset}.INFORMATION_SCHEMA.COLUMNS` WHERE TABLE_NAME = '{args.bq_table}'\"\n",
       "schema = bq.query(query).to_dataframe()\n",
       "\n",
       "# get number of classes from bigquery source\n",
       "nclasses = bq.query(query = f'SELECT DISTINCT {VAR_TARGET} FROM `{args.bq_project}.{args.bq_dataset}.{args.bq_table}` WHERE {VAR_TARGET} is not null').to_dataframe()\n",
       "nclasses = nclasses.shape[0]\n",
       "expRun.log_params({'data_source': f'bq://{args.bq_project}.{args.bq_dataset}.{args.bq_table}', 'nclasses': nclasses, 'var_split': 'splits', 'var_target': VAR_TARGET})\n",
       "\n",
       "train_query = f\"SELECT * FROM `{args.bq_project}.{args.bq_dataset}.{args.bq_table}` WHERE splits = 'TRAIN'\"\n",
       "train = bq.query(train_query).to_dataframe()\n",
       "X_train = train.loc[:, ~train.columns.isin(VAR_OMIT)]\n",
       "y_train = train[VAR_TARGET].astype('int')\n",
       "\n",
       "val_query = f\"SELECT * FROM `{args.bq_project}.{args.bq_dataset}.{args.bq_table}` WHERE splits = 'VALIDATE'\"\n",
       "val = bq.query(val_query).to_dataframe()\n",
       "X_val = val.loc[:, ~val.columns.isin(VAR_OMIT)]\n",
       "y_val = val[VAR_TARGET].astype('int')\n",
       "\n",
       "test_query = f\"SELECT * FROM `{args.bq_project}.{args.bq_dataset}.{args.bq_table}` WHERE splits = 'TEST'\"\n",
       "test = bq.query(test_query).to_dataframe()\n",
       "X_test = test.loc[:, ~test.columns.isin(VAR_OMIT)]\n",
       "y_test = test[VAR_TARGET].astype('int')\n",
       "\n",
       "# Logistic Regression\n",
       "# instantiate the model \n",
       "logistic = LogisticRegression(solver=args.solver, penalty=args.penalty)\n",
       "\n",
       "# Define a Standard Scaler to normalize inputs\n",
       "scaler = StandardScaler()\n",
       "\n",
       "expRun.log_params({'solver': args.solver, 'penalty': args.penalty})\n",
       "\n",
       "# define pipeline\n",
       "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"logistic\", logistic)])\n",
       "\n",
       "# define grid search model\n",
       "model = pipe.fit(X_train, y_train)\n",
       "\n",
       "# test evaluations:\n",
       "y_pred = model.predict(X_test)\n",
       "test_acc = metrics.accuracy_score(y_test, y_pred) \n",
       "test_prec = metrics.precision_score(y_test, y_pred)\n",
       "test_rec = metrics.recall_score(y_test, y_pred)\n",
       "test_rocauc = metrics.roc_auc_score(y_test, y_pred)\n",
       "expRun.log_metrics({'test_accuracy': test_acc, 'test_precision': test_prec, 'test_recall': test_rec, 'test_roc_auc': test_rocauc})\n",
       "\n",
       "# val evaluations:\n",
       "y_pred_val = model.predict(X_val)\n",
       "val_acc = metrics.accuracy_score(y_val, y_pred_val) \n",
       "val_prec = metrics.precision_score(y_val, y_pred_val)\n",
       "val_rec = metrics.recall_score(y_val, y_pred_val)\n",
       "val_rocauc = metrics.roc_auc_score(y_val, y_pred_val)\n",
       "expRun.log_metrics({'validation_accuracy': val_acc, 'validation_precision': val_prec, 'validation_recall': val_rec, 'validation_roc_auc': val_rocauc})\n",
       "\n",
       "# training evaluations:\n",
       "y_pred_training = model.predict(X_train)\n",
       "training_acc = metrics.accuracy_score(y_train, y_pred_training) \n",
       "training_prec = metrics.precision_score(y_train, y_pred_training)\n",
       "training_rec = metrics.recall_score(y_train, y_pred_training)\n",
       "training_rocauc = metrics.roc_auc_score(y_train, y_pred_training)\n",
       "expRun.log_metrics({'training_accuracy': training_acc, 'training_precision':training_prec, 'training_recall': training_rec, 'training_roc_auc': training_rocauc})\n",
       "\n",
       "file_name = 'model.pkl'\n",
       "\n",
       "# Use predefined environment variable to establish model directory\n",
       "model_directory = os.environ['AIP_MODEL_DIR']\n",
       "storage_path = f'/gcs/{model_directory[5:]}' + file_name\n",
       "os.makedirs(os.path.dirname(storage_path), exist_ok=True)\n",
       "\n",
       "# output the model save files directly to GCS destination\n",
       "with open(storage_path,'wb') as f:\n",
       "    pickle.dump(model,f)\n",
       "\n",
       "expRun.log_params({'model.save': storage_path})\n",
       "expRun.end_run()\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCRIPT_PATH = './code/train.py'\n",
    "\n",
    "with open(SCRIPT_PATH, 'r') as file:\n",
    "    data = file.read()\n",
    "md(f\"```python\\n\\n{data}\\n```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Custom Container with Cloud Build\n",
    "\n",
    "Cloud Build creates and manages the build on GCP.  The API creates a build by providing:\n",
    "- location of the source\n",
    "- instructions\n",
    "- location to store the built artifacts\n",
    "\n",
    "The instruction part of Cloud Build has options:\n",
    "- Dockerfile\n",
    "- Build Config file (YAML or JSON)\n",
    "- Cloud Native Buildpacks\n",
    "\n",
    "This notebook uses the approach of using the Python Client for Cloud Build and not referencing any local files.  For that reason, the first step is creating a Dockerfile for the workflow and storing it in GCS. The next step is running Cloud Build and using the client to specify the Build config rather than a config file.  The steps of the build config start with getting the code (git clone, or copy from GCS) and copying the Dockerfile.  \n",
    "\n",
    "There are many workflows for creating containers with ML training code.  Many of the most common ones are explored in the tips notebook [Python Custom Containers](../Tips/Python%20Custom%20Containers.ipynb).  The method used here is the simplest - copy the training code directly into the container.  The other methods include packaging the training code as a Python Distribution and using `pip install` in from GCS, GitHub and even Artifact Registry as a private repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store Resources in Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = gcs.lookup_bucket(PROJECT_ID)\n",
    "SOURCEPATH = f'{SERIES}/{EXPERIMENT}/training'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = bucket.blob(f'{SOURCEPATH}/{EXPERIMENT}_trainer/train.py')\n",
    "blob.upload_from_filename(SCRIPT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Requirements.txt File for Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "requirements = f\"\"\"google-cloud-aiplatform\n",
    "protobuf\n",
    "db-dtypes>=1.0.0\n",
    "google-auth>=2.6.0\n",
    "google-cloud-bigquery>=3.0.1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = bucket.blob(f'{SOURCEPATH}/requirements.txt')\n",
    "blob.upload_from_string(requirements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the Dockerfile\n",
    "A basic dockerfile thats take the base image and copies the code in and define an entrypoint - what python script to run first in this case.  Add RUN entries to pip install additional packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dockerfile = f\"\"\"\n",
    "FROM {BASE_IMAGE}\n",
    "WORKDIR /training\n",
    "# copy requirements and install them\n",
    "COPY requirements.txt ./\n",
    "RUN pip install --no-cache-dir --upgrade pip \\\n",
    "  && pip install --no-cache-dir -r requirements.txt\n",
    "## Copies the trainer code to the docker image\n",
    "COPY {EXPERIMENT}_trainer/* ./{EXPERIMENT}_trainer/\n",
    "## Sets up the entry point to invoke the trainer\n",
    "ENTRYPOINT [\"python\", \"-m\", \"{EXPERIMENT}_trainer.train\"]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = bucket.blob(f'{SOURCEPATH}/Dockerfile')\n",
    "blob.upload_from_string(dockerfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup Artifact Registry\n",
    "\n",
    "Artifact registry organizes artifacts with repositories.  Each repository contains packages and is designated to hold a partifcular format of package: Docker images, Python Packages and [others](https://cloud.google.com/artifact-registry/docs/supported-formats#package)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### List Repositories\n",
    "\n",
    "This may be empty if no repositories have been created for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects/demos-vertex-ai/locations/us-central1/repositories/automl-beans\n",
      "projects/demos-vertex-ai/locations/us-central1/repositories/bcbs-tn-pam-repo\n",
      "projects/demos-vertex-ai/locations/us-central1/repositories/cloud-workstations-external-copy\n",
      "projects/demos-vertex-ai/locations/us-central1/repositories/demos-vertex-ai\n",
      "projects/demos-vertex-ai/locations/us-central1/repositories/doc-qna\n",
      "projects/demos-vertex-ai/locations/us-central1/repositories/doc-qna-cw-rstudio\n",
      "projects/demos-vertex-ai/locations/us-central1/repositories/dow-10-k-gemini-repo\n",
      "projects/demos-vertex-ai/locations/us-central1/repositories/fruit-and-vegetable-image-model-repo\n",
      "projects/demos-vertex-ai/locations/us-central1/repositories/fruit-veg-disease-model-kaggle\n",
      "projects/demos-vertex-ai/locations/us-central1/repositories/fruit-veg-image-classification\n",
      "projects/demos-vertex-ai/locations/us-central1/repositories/fruit-veg-image-model\n",
      "projects/demos-vertex-ai/locations/us-central1/repositories/fruit-veg-image-model-imagen-repo\n",
      "projects/demos-vertex-ai/locations/us-central1/repositories/fruit-veg-image-model-kaggle\n",
      "projects/demos-vertex-ai/locations/us-central1/repositories/gcf-artifacts\n",
      "projects/demos-vertex-ai/locations/us-central1/repositories/imagen-classification-poc\n",
      "projects/demos-vertex-ai/locations/us-central1/repositories/imagen-classification-serving-poc\n",
      "projects/demos-vertex-ai/locations/us-central1/repositories/my-docker-repo\n",
      "projects/demos-vertex-ai/locations/us-central1/repositories/patient-summary\n",
      "projects/demos-vertex-ai/locations/us-central1/repositories/patient-summary-dev\n",
      "projects/demos-vertex-ai/locations/us-central1/repositories/posit-rstudio-server\n",
      "projects/demos-vertex-ai/locations/us-central1/repositories/r-model-02\n",
      "projects/demos-vertex-ai/locations/us-central1/repositories/r-on-vertex\n",
      "projects/demos-vertex-ai/locations/us-central1/repositories/r-test-repo\n",
      "projects/demos-vertex-ai/locations/us-central1/repositories/rstudio\n",
      "projects/demos-vertex-ai/locations/us-central1/repositories/rstudio-cloud-workstations\n",
      "projects/demos-vertex-ai/locations/us-central1/repositories/shiny-run\n",
      "projects/demos-vertex-ai/locations/us-central1/repositories/vertex-r-batch\n"
     ]
    }
   ],
   "source": [
    "for repo in ar_client.list_repositories(parent = f'projects/{PROJECT_ID}/locations/{REGION}'):\n",
    "    print(repo.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Docker Image Repository\n",
    "\n",
    "Create an Artifact Registry Repository to hold Docker Images created by this notebook.  First, check to see if it is already created by a previous run and retrieve it if it has.  Otherwise, create!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved existing repo: projects/demos-vertex-ai/locations/us-central1/repositories/demos-vertex-ai\n"
     ]
    }
   ],
   "source": [
    "docker_repo = None\n",
    "for repo in ar_client.list_repositories(parent = f'projects/{PROJECT_ID}/locations/{REGION}'):\n",
    "    if f'{PROJECT_ID}' == repo.name.split('/')[-1]:\n",
    "        docker_repo = repo\n",
    "        print(f'Retrieved existing repo: {docker_repo.name}')\n",
    "\n",
    "if not docker_repo:\n",
    "    operation = ar_client.create_repository(\n",
    "        request = artifactregistry_v1.CreateRepositoryRequest(\n",
    "            parent = f'projects/{PROJECT_ID}/locations/{REGION}',\n",
    "            repository_id = f'{PROJECT_ID}',\n",
    "            repository = artifactregistry_v1.Repository(\n",
    "                description = f'A repository for the {EXPERIMENT} experiment that holds docker images.',\n",
    "                name = f'{PROJECT_ID}',\n",
    "                format_ = artifactregistry_v1.Repository.Format.DOCKER,\n",
    "                labels = {'series': SERIES, 'experiment': EXPERIMENT}\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    print('Creating Repository ...')\n",
    "    docker_repo = operation.result()\n",
    "    print(f'Completed creating repo: {docker_repo.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('projects/demos-vertex-ai/locations/us-central1/repositories/demos-vertex-ai',\n",
       " 'DOCKER')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docker_repo.name, docker_repo.format_.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPOSITORY = f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{docker_repo.name.split('/')[-1]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Custom Container\n",
    "Use the Cloud Build client to construct and run the build instructions.  Here the files collected in GCS are copied to the build instance, then the Docker build in run in the folder with the `Dockerfile`.  The resulting image is pushed to Artifact Registry (setup above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the build config with empty list of steps - these will be added sequentially\n",
    "build = cloudbuild_v1.Build(\n",
    "    steps = []\n",
    ")\n",
    "# retrieve the source\n",
    "build.steps.append(\n",
    "    {\n",
    "        'name': 'gcr.io/cloud-builders/gsutil',\n",
    "        'args': ['cp', '-r', f'gs://{PROJECT_ID}/{SOURCEPATH}/*', '/workspace']\n",
    "    }\n",
    ")\n",
    "# docker build\n",
    "build.steps.append(\n",
    "    {\n",
    "        'name': 'gcr.io/cloud-builders/docker',\n",
    "        'args': ['build', '-t', f'{REPOSITORY}/{EXPERIMENT}_trainer', '/workspace']\n",
    "    }    \n",
    ")\n",
    "# docker push\n",
    "build.images = [f\"{REPOSITORY}/{EXPERIMENT}_trainer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "steps {\n",
       "  name: \"gcr.io/cloud-builders/gsutil\"\n",
       "  args: \"cp\"\n",
       "  args: \"-r\"\n",
       "  args: \"gs://demos-vertex-ai/03/03f/training/*\"\n",
       "  args: \"/workspace\"\n",
       "}\n",
       "steps {\n",
       "  name: \"gcr.io/cloud-builders/docker\"\n",
       "  args: \"build\"\n",
       "  args: \"-t\"\n",
       "  args: \"us-central1-docker.pkg.dev/demos-vertex-ai/demos-vertex-ai/03f_trainer\"\n",
       "  args: \"/workspace\"\n",
       "}\n",
       "images: \"us-central1-docker.pkg.dev/demos-vertex-ai/demos-vertex-ai/03f_trainer\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "operation = cb_client.create_build(\n",
    "    project_id = PROJECT_ID,\n",
    "    build = build\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Status.SUCCESS: 3>,\n",
       " images: \"us-central1-docker.pkg.dev/demos-vertex-ai/demos-vertex-ai/03f_trainer\")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = operation.result()\n",
    "response.status, response.artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review the Custom Container with Artifact Registry in the Google Cloud Console:\n",
      "https://console.cloud.google.com/artifacts/docker/demos-vertex-ai/us-central1/demos-vertex-ai-docker?project=demos-vertex-ai\n"
     ]
    }
   ],
   "source": [
    "print(f\"Review the Custom Container with Artifact Registry in the Google Cloud Console:\\nhttps://console.cloud.google.com/artifacts/docker/{PROJECT_ID}/{REGION}/{PROJECT_ID}-docker?project={PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Training Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMDARGS = [\n",
    "    \"--penalty=\" + PENALTY,\n",
    "    \"--solver=\" + SOLVER,\n",
    "    \"--var_target=\" + VAR_TARGET,\n",
    "    \"--var_omit=\" + VAR_OMIT,\n",
    "    \"--project_id=\" + PROJECT_ID,\n",
    "    \"--bq_project=\" + BQ_PROJECT,\n",
    "    \"--bq_dataset=\" + BQ_DATASET,\n",
    "    \"--bq_table=\" + BQ_TABLE,\n",
    "    \"--region=\" + REGION,\n",
    "    \"--experiment=\" + EXPERIMENT,\n",
    "    \"--series=\" + SERIES,\n",
    "    \"--experiment_name=\" + EXPERIMENT_NAME,\n",
    "    \"--run_name=\" + RUN_NAME\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingJob = aiplatform.CustomContainerTrainingJob(\n",
    "    display_name = f'{SERIES}_{EXPERIMENT}_{TIMESTAMP}',\n",
    "    container_uri = f\"{REPOSITORY}/{EXPERIMENT}_trainer\",\n",
    "    model_serving_container_image_uri = DEPLOY_IMAGE,\n",
    "    staging_bucket = f\"{URI}/models/{TIMESTAMP}\",\n",
    "    labels = {'series' : f'{SERIES}', 'experiment' : f'{EXPERIMENT}', 'experiment_name' : f'{EXPERIMENT_NAME}', 'run_name' : f'{RUN_NAME}'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Training Job AND Upload The Model\n",
    "The training job will automatically upload the model to the Vertex AI Model Registry and return the link to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Already in Registry:\n",
      "Loading model as new default version.\n",
      "Training Output directory:\n",
      "gs://demos-vertex-ai/03/03f/models/20250123163434 \n",
      "View Training:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/4728236965390974976?project=746038361521\n",
      "CustomContainerTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/4728236965390974976 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "View backing custom job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/93663512919801856?project=746038361521\n",
      "CustomContainerTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/4728236965390974976 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomContainerTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/4728236965390974976 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomContainerTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/4728236965390974976 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomContainerTrainingJob projects/746038361521/locations/us-central1/trainingPipelines/4728236965390974976 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "CustomContainerTrainingJob run completed. Resource name: projects/746038361521/locations/us-central1/trainingPipelines/4728236965390974976\n",
      "Model available at projects/746038361521/locations/us-central1/models/model_03_03f\n"
     ]
    }
   ],
   "source": [
    "modelmatch = aiplatform.Model.list(filter = f'display_name={SERIES}_{EXPERIMENT} AND labels.series={SERIES} AND labels.experiment={EXPERIMENT}')\n",
    "\n",
    "upload_model = True\n",
    "if modelmatch:\n",
    "    print(\"Model Already in Registry:\")\n",
    "    if RUN_NAME in modelmatch[0].version_aliases:\n",
    "        print(\"This version already loaded, no action taken.\")\n",
    "        upload_model = False\n",
    "        model = aiplatform.Model(model_name = modelmatch[0].resource_name)\n",
    "    else:\n",
    "        print('Loading model as new default version.')\n",
    "        parent_model = modelmatch[0].resource_name\n",
    "else:\n",
    "    print('This is a new model, creating in model registry')\n",
    "    parent_model = ''\n",
    "    \n",
    "if upload_model:\n",
    "    model = trainingJob.run(\n",
    "        model_display_name = f'{SERIES}_{EXPERIMENT}',\n",
    "        model_labels = {'series' : f'{SERIES}', 'experiment' : f'{EXPERIMENT}', 'experiment_name' : f'{EXPERIMENT_NAME}', 'run_name' : f'{RUN_NAME}'},\n",
    "        model_id = f'model_{SERIES}_{EXPERIMENT}',\n",
    "        parent_model = parent_model,\n",
    "        is_default_version = True,\n",
    "        model_version_aliases = [RUN_NAME],\n",
    "        model_version_description = RUN_NAME,\n",
    "        base_output_dir = f\"{URI}/models/{TIMESTAMP}\",\n",
    "        service_account = SERVICE_ACCOUNT,\n",
    "        args = CMDARGS,\n",
    "        replica_count = 1,\n",
    "        machine_type = TRAIN_COMPUTE,\n",
    "        accelerator_count = 0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the backing Custom Job for the Training Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "clientPL = aiplatform.gapic.PipelineServiceClient(client_options = {'api_endpoint': f'{REGION}-aiplatform.googleapis.com'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.protobuf.json_format import MessageToDict\n",
    "\n",
    "backingCustomJob = MessageToDict(clientPL.get_training_pipeline(name = trainingJob.resource_name)._pb)['trainingTaskMetadata']['backingCustomJob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('projects/746038361521/locations/us-central1/customJobs/93663512919801856',\n",
       " '03_03f_20250123163434-custom-job')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customJob = aiplatform.CustomJob.get(backingCustomJob)\n",
    "customJob.resource_name, customJob.display_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create hyperlinks to job and model here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review the Training Pipeline here:\n",
      "https://console.cloud.google.com/vertex-ai/training/training-pipelines?project=demos-vertex-ai\n",
      "Review the Custom Job here:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/training/93663512919801856/cpu?cloudshell=false&project=demos-vertex-ai\n",
      "Review the model in the Vertex AI Model Registry:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/models/model_03_03f?project=demos-vertex-ai\n"
     ]
    }
   ],
   "source": [
    "job_link = f\"https://console.cloud.google.com/vertex-ai/locations/{REGION}/training/{customJob.resource_name.split('/')[-1]}/cpu?cloudshell=false&project={PROJECT_ID}\"\n",
    "\n",
    "print(f'Review the Training Pipeline here:\\nhttps://console.cloud.google.com/vertex-ai/training/training-pipelines?project={PROJECT_ID}')\n",
    "print(f'Review the Custom Job here:\\n{job_link}')\n",
    "print(f'Review the model in the Vertex AI Model Registry:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/models/{model.name}?project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vertex AI Experiment Update and Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "expRun = aiplatform.ExperimentRun(run_name = RUN_NAME, experiment = EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "expRun.log_params({\n",
    "    'model.uri': model.uri,\n",
    "    'model.display_name': model.display_name,\n",
    "    'model.name': model.name,\n",
    "    'model.resource_name': model.resource_name,\n",
    "    'model.version_id': model.version_id,\n",
    "    'model.versioned_resource_name': model.versioned_resource_name,\n",
    "    'trainingPipelines.display_name': trainingJob.display_name,\n",
    "    'trainingPipelines.resource_name': trainingJob.resource_name,\n",
    "    'customJobs.display_name': customJob.display_name,\n",
    "    'customJobs.resource_name': customJob.resource_name,\n",
    "    'customJobs.link': job_link\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the experiment run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "expRun.update_state(state = aiplatform.gapic.Execution.State.COMPLETE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = aiplatform.Experiment(experiment_name = EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>run_type</th>\n",
       "      <th>state</th>\n",
       "      <th>param.customJobs.link</th>\n",
       "      <th>param.solver</th>\n",
       "      <th>param.project_id</th>\n",
       "      <th>param.customJobs.resource_name</th>\n",
       "      <th>param.experiment</th>\n",
       "      <th>param.model.version_id</th>\n",
       "      <th>...</th>\n",
       "      <th>metric.test_accuracy</th>\n",
       "      <th>metric.validation_precision</th>\n",
       "      <th>metric.validation_accuracy</th>\n",
       "      <th>metric.validation_recall</th>\n",
       "      <th>metric.test_recall</th>\n",
       "      <th>metric.test_precision</th>\n",
       "      <th>metric.training_recall</th>\n",
       "      <th>metric.validation_roc_auc</th>\n",
       "      <th>metric.training_precision</th>\n",
       "      <th>metric.training_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>experiment-03-03f-sklearn-classification-logis...</td>\n",
       "      <td>run-20250123163434</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>https://console.cloud.google.com/vertex-ai/loc...</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>demos-vertex-ai</td>\n",
       "      <td>projects/746038361521/locations/us-central1/cu...</td>\n",
       "      <td>03f</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999195</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.999086</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.634961</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.879004</td>\n",
       "      <td>0.999227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>experiment-03-03f-sklearn-classification-logis...</td>\n",
       "      <td>run-20250123151707</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>https://console.cloud.google.com/vertex-ai/loc...</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>demos-vertex-ai</td>\n",
       "      <td>projects/746038361521/locations/us-central1/cu...</td>\n",
       "      <td>03f</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999195</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.999086</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.634961</td>\n",
       "      <td>0.812412</td>\n",
       "      <td>0.879004</td>\n",
       "      <td>0.999227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     experiment_name            run_name  \\\n",
       "0  experiment-03-03f-sklearn-classification-logis...  run-20250123163434   \n",
       "1  experiment-03-03f-sklearn-classification-logis...  run-20250123151707   \n",
       "\n",
       "               run_type     state  \\\n",
       "0  system.ExperimentRun  COMPLETE   \n",
       "1  system.ExperimentRun  COMPLETE   \n",
       "\n",
       "                               param.customJobs.link param.solver  \\\n",
       "0  https://console.cloud.google.com/vertex-ai/loc...    newton-cg   \n",
       "1  https://console.cloud.google.com/vertex-ai/loc...    newton-cg   \n",
       "\n",
       "  param.project_id                     param.customJobs.resource_name  \\\n",
       "0  demos-vertex-ai  projects/746038361521/locations/us-central1/cu...   \n",
       "1  demos-vertex-ai  projects/746038361521/locations/us-central1/cu...   \n",
       "\n",
       "  param.experiment param.model.version_id  ... metric.test_accuracy  \\\n",
       "0              03f                      2  ...             0.999195   \n",
       "1              03f                      1  ...             0.999195   \n",
       "\n",
       "  metric.validation_precision metric.validation_accuracy  \\\n",
       "0                       0.875                   0.999086   \n",
       "1                       0.875                   0.999086   \n",
       "\n",
       "  metric.validation_recall metric.test_recall metric.test_precision  \\\n",
       "0                    0.625           0.595745                 0.875   \n",
       "1                    0.625           0.595745                 0.875   \n",
       "\n",
       "  metric.training_recall metric.validation_roc_auc metric.training_precision  \\\n",
       "0               0.634961                  0.812412                  0.879004   \n",
       "1               0.634961                  0.812412                  0.879004   \n",
       "\n",
       "   metric.training_accuracy  \n",
       "0                  0.999227  \n",
       "1                  0.999227  \n",
       "\n",
       "[2 rows x 37 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.get_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Experiment and Run in Console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review The Experiment in the Console:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/experiments/experiment-03-03f-sklearn-classification-logistric-regression?project=demos-vertex-ai\n"
     ]
    }
   ],
   "source": [
    "print(f'Review The Experiment in the Console:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/experiments/{EXPERIMENT_NAME}?project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review The Experiment Run in the Console:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/experiments/experiment-03-03f-sklearn-classification-logistric-regression/runs/experiment-03-03f-sklearn-classification-logistric-regression-run-20250123163434?project=demos-vertex-ai\n"
     ]
    }
   ],
   "source": [
    "print(f'Review The Experiment Run in the Console:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/experiments/{EXPERIMENT_NAME}/runs/{EXPERIMENT_NAME}-{RUN_NAME}?project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare This Run Using Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Get a list of all experiments in this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = aiplatform.Experiment.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove experiments not in the SERIES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [e for e in experiments if e.name.split('-')[0:2] == ['experiment', SERIES]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the runs from all experiments in SERIES into a single dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment-03-03f-sklearn-classification-logistric-regression\n",
      "experiment-03-03d-sklearn-classification-logistric-regression\n",
      "experiment-03-03a-sklearn-classification-logistric-regression\n",
      "experiment-03-03-sklearn-classification-logistic-regression\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for experiment in experiments:\n",
    "        results.append(experiment.get_data_frame())\n",
    "        print(experiment.name)\n",
    "results = pd.concat(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create ranks for models within experiment and across the entire SERIES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>param.model.display_name</th>\n",
       "      <th>param.model.version_id</th>\n",
       "      <th>metric.test_roc_auc</th>\n",
       "      <th>series_rank</th>\n",
       "      <th>experiment_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>experiment-03-03-sklearn-classification-logist...</td>\n",
       "      <td>run-20250121203058</td>\n",
       "      <td>03_03</td>\n",
       "      <td>2</td>\n",
       "      <td>0.797802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>experiment-03-03a-sklearn-classification-logis...</td>\n",
       "      <td>run-20250122204938</td>\n",
       "      <td>03_03a</td>\n",
       "      <td>1</td>\n",
       "      <td>0.797802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>experiment-03-03a-sklearn-classification-logis...</td>\n",
       "      <td>run-20250122212307</td>\n",
       "      <td>03_03a</td>\n",
       "      <td>2</td>\n",
       "      <td>0.797802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>experiment-03-03d-sklearn-classification-logis...</td>\n",
       "      <td>run-20250122180418</td>\n",
       "      <td>03_03d</td>\n",
       "      <td>1</td>\n",
       "      <td>0.797802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>experiment-03-03f-sklearn-classification-logis...</td>\n",
       "      <td>run-20250123151707</td>\n",
       "      <td>03_03f</td>\n",
       "      <td>1</td>\n",
       "      <td>0.797802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>experiment-03-03f-sklearn-classification-logis...</td>\n",
       "      <td>run-20250123163434</td>\n",
       "      <td>03_03f</td>\n",
       "      <td>2</td>\n",
       "      <td>0.797802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     experiment_name            run_name  \\\n",
       "5  experiment-03-03-sklearn-classification-logist...  run-20250121203058   \n",
       "4  experiment-03-03a-sklearn-classification-logis...  run-20250122204938   \n",
       "3  experiment-03-03a-sklearn-classification-logis...  run-20250122212307   \n",
       "2  experiment-03-03d-sklearn-classification-logis...  run-20250122180418   \n",
       "1  experiment-03-03f-sklearn-classification-logis...  run-20250123151707   \n",
       "0  experiment-03-03f-sklearn-classification-logis...  run-20250123163434   \n",
       "\n",
       "  param.model.display_name param.model.version_id  metric.test_roc_auc  \\\n",
       "5                    03_03                      2             0.797802   \n",
       "4                   03_03a                      1             0.797802   \n",
       "3                   03_03a                      2             0.797802   \n",
       "2                   03_03d                      1             0.797802   \n",
       "1                   03_03f                      1             0.797802   \n",
       "0                   03_03f                      2             0.797802   \n",
       "\n",
       "   series_rank  experiment_rank  \n",
       "5          1.0              1.0  \n",
       "4          1.0              1.0  \n",
       "3          1.0              1.0  \n",
       "2          1.0              1.0  \n",
       "1          1.0              1.0  \n",
       "0          1.0              1.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ranker(metric = 'metric.test_roc_auc'):\n",
    "    ranks = results[['experiment_name', 'run_name', 'param.model.display_name', 'param.model.version_id', metric]].copy().reset_index(drop = True)\n",
    "    ranks['series_rank'] = ranks[metric].rank(method = 'dense', ascending = False)\n",
    "    ranks['experiment_rank'] = ranks.groupby('experiment_name')[metric].rank(method = 'dense', ascending = False)\n",
    "    return ranks.sort_values(by = ['experiment_name', 'run_name'])\n",
    "    \n",
    "ranks = ranker('metric.test_roc_auc')\n",
    "ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>param.model.display_name</th>\n",
       "      <th>param.model.version_id</th>\n",
       "      <th>metric.test_roc_auc</th>\n",
       "      <th>series_rank</th>\n",
       "      <th>experiment_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>experiment-03-03f-sklearn-classification-logis...</td>\n",
       "      <td>run-20250123163434</td>\n",
       "      <td>03_03f</td>\n",
       "      <td>2</td>\n",
       "      <td>0.797802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     experiment_name            run_name  \\\n",
       "0  experiment-03-03f-sklearn-classification-logis...  run-20250123163434   \n",
       "\n",
       "  param.model.display_name param.model.version_id  metric.test_roc_auc  \\\n",
       "0                   03_03f                      2             0.797802   \n",
       "\n",
       "   series_rank  experiment_rank  \n",
       "0          1.0              1.0  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_rank = ranks.loc[(ranks['param.model.display_name'] == model.display_name) & (ranks['param.model.version_id'] == model.version_id)]\n",
    "current_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current model is ranked 1.0 within this experiment and 1.0 across this series.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The current model is ranked {current_rank['experiment_rank'].iloc[0]} within this experiment and {current_rank['series_rank'].iloc[0]} across this series.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create/Retrieve The Endpoint For This Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/746038361521/locations/us-central1/endpoints/389096274348998656/operations/5130469586193350656\n",
      "Endpoint created. Resource name: projects/746038361521/locations/us-central1/endpoints/389096274348998656\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/746038361521/locations/us-central1/endpoints/389096274348998656')\n",
      "Endpoint Created: projects/746038361521/locations/us-central1/endpoints/389096274348998656\n",
      "Review the Endpoint in the Console:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/endpoints/389096274348998656?project=demos-vertex-ai\n"
     ]
    }
   ],
   "source": [
    "endpoints = aiplatform.Endpoint.list(filter = f\"labels.series={SERIES}\")\n",
    "if endpoints:\n",
    "    endpoint = endpoints[0]\n",
    "    print(f\"Endpoint Exists: {endpoints[0].resource_name}\")\n",
    "else:\n",
    "    endpoint = aiplatform.Endpoint.create(\n",
    "        display_name = f\"{SERIES}\",\n",
    "        labels = {'series' : f\"{SERIES}\"}    \n",
    "    )\n",
    "    print(f\"Endpoint Created: {endpoint.resource_name}\")\n",
    "    \n",
    "print(f'Review the Endpoint in the Console:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/endpoints/{endpoint.name}?project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'03'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.display_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.traffic_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deployed_models = endpoint.list_models()\n",
    "deployed_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Should This Model Be Deployed?\n",
    "Is it better than the model already deployed on the endpoint?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No models currently deployed.\n"
     ]
    }
   ],
   "source": [
    "deploy = False\n",
    "if deployed_models:\n",
    "    for deployed_model in deployed_models:\n",
    "        deployed_rank = ranks.loc[(ranks['param.model.display_name'] == deployed_model.display_name) & (ranks['param.model.version_id'] == deployed_model.model_version_id)]['series_rank'].iloc[0]\n",
    "        model_rank = current_rank['series_rank'].iloc[0]\n",
    "        if deployed_model.display_name == model.display_name and deployed_model.model_version_id == model.version_id:\n",
    "            print(f'The current model/version is already deployed.')\n",
    "            break\n",
    "        elif model_rank <= deployed_rank:\n",
    "            deploy = True\n",
    "            print(f'The current model is ranked better ({model_rank}) than a currently deployed model ({deployed_rank}).')\n",
    "            break\n",
    "    if deploy == False: print(f'The current model is ranked worse ({model_rank}) than a currently deployed model ({deployed_rank})')\n",
    "else: \n",
    "    deploy = True\n",
    "    print('No models currently deployed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy Model To Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying model with 100% of traffic...\n",
      "Deploying Model projects/746038361521/locations/us-central1/models/model_03_03f to Endpoint : projects/746038361521/locations/us-central1/endpoints/389096274348998656\n",
      "Deploy Endpoint model backing LRO: projects/746038361521/locations/us-central1/endpoints/389096274348998656/operations/8652284494797078528\n",
      "Endpoint model deployed. Resource name: projects/746038361521/locations/us-central1/endpoints/389096274348998656\n"
     ]
    }
   ],
   "source": [
    "if deploy:\n",
    "    print(f'Deploying model with 100% of traffic...')\n",
    "    endpoint.deploy(\n",
    "        model = model,\n",
    "        deployed_model_display_name = model.display_name,\n",
    "        traffic_percentage = 100,\n",
    "        machine_type = DEPLOY_COMPUTE,\n",
    "        min_replica_count = 1,\n",
    "        max_replica_count = 1\n",
    "    )\n",
    "else: print(f'Not deploying - current model is worse ({model_rank}) than the currently deployed model ({deployed_rank})') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Deployed Models without Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 03_03f with version 2 has traffic = 100\n"
     ]
    }
   ],
   "source": [
    "for deployed_model in endpoint.list_models():\n",
    "    if deployed_model.id in endpoint.traffic_split:\n",
    "        print(f\"Model {deployed_model.display_name} with version {deployed_model.model_version_id} has traffic = {endpoint.traffic_split[deployed_model.id]}\")\n",
    "    else:\n",
    "        endpoint.undeploy(deployed_model_id = deployed_model.id)\n",
    "        print(f\"Undeploying {deployed_model.display_name} with version {deployed_model.model_version_id} because it has no traffic.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'147480793168478208': 100}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.traffic_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#endpoint.list_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Prediction\n",
    "\n",
    "See many more details on requesting predictions in the [05Tools - Prediction](./05Tools%20-%20Prediction.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare a record for prediction: instance and parameters lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "pred = bq.query(\n",
    "    query = f\"\"\"\n",
    "        SELECT * EXCEPT({VAR_OMIT.replace('-', ',')})\n",
    "        FROM `{BQ_PROJECT}.{BQ_DATASET}.{BQ_TABLE}`\n",
    "        WHERE splits='TEST'\n",
    "        LIMIT {n}\n",
    "        \"\"\"\n",
    ").to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>430</td>\n",
       "      <td>-1.860258</td>\n",
       "      <td>-0.629859</td>\n",
       "      <td>0.966570</td>\n",
       "      <td>0.844632</td>\n",
       "      <td>0.759983</td>\n",
       "      <td>-1.481173</td>\n",
       "      <td>-0.509681</td>\n",
       "      <td>0.540722</td>\n",
       "      <td>-0.733623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.320450</td>\n",
       "      <td>0.268028</td>\n",
       "      <td>0.125515</td>\n",
       "      <td>-0.225029</td>\n",
       "      <td>0.586664</td>\n",
       "      <td>-0.031598</td>\n",
       "      <td>0.570168</td>\n",
       "      <td>-0.043007</td>\n",
       "      <td>-0.223739</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59251</td>\n",
       "      <td>1.331040</td>\n",
       "      <td>0.052830</td>\n",
       "      <td>0.158259</td>\n",
       "      <td>-0.151706</td>\n",
       "      <td>-0.412906</td>\n",
       "      <td>-0.993280</td>\n",
       "      <td>0.020417</td>\n",
       "      <td>-0.210561</td>\n",
       "      <td>0.272057</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084019</td>\n",
       "      <td>-0.259684</td>\n",
       "      <td>-0.751655</td>\n",
       "      <td>0.072844</td>\n",
       "      <td>0.072357</td>\n",
       "      <td>0.210818</td>\n",
       "      <td>0.870251</td>\n",
       "      <td>-0.089094</td>\n",
       "      <td>-0.000475</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>148181</td>\n",
       "      <td>0.066427</td>\n",
       "      <td>1.824822</td>\n",
       "      <td>-0.957376</td>\n",
       "      <td>4.224416</td>\n",
       "      <td>1.770814</td>\n",
       "      <td>0.334517</td>\n",
       "      <td>0.840841</td>\n",
       "      <td>0.154274</td>\n",
       "      <td>-2.838745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166637</td>\n",
       "      <td>0.300908</td>\n",
       "      <td>0.793573</td>\n",
       "      <td>-0.054356</td>\n",
       "      <td>0.086829</td>\n",
       "      <td>-0.963660</td>\n",
       "      <td>0.317822</td>\n",
       "      <td>0.160572</td>\n",
       "      <td>0.177744</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>148365</td>\n",
       "      <td>-0.625474</td>\n",
       "      <td>1.303970</td>\n",
       "      <td>-0.001461</td>\n",
       "      <td>0.580589</td>\n",
       "      <td>0.372016</td>\n",
       "      <td>-0.411669</td>\n",
       "      <td>0.412633</td>\n",
       "      <td>0.474088</td>\n",
       "      <td>-1.503261</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.216152</td>\n",
       "      <td>0.308786</td>\n",
       "      <td>0.650292</td>\n",
       "      <td>-0.048038</td>\n",
       "      <td>-0.271956</td>\n",
       "      <td>-1.008158</td>\n",
       "      <td>2.250184</td>\n",
       "      <td>-0.026950</td>\n",
       "      <td>0.163204</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>282</td>\n",
       "      <td>-0.356466</td>\n",
       "      <td>0.725418</td>\n",
       "      <td>1.971749</td>\n",
       "      <td>0.831343</td>\n",
       "      <td>0.369681</td>\n",
       "      <td>-0.107776</td>\n",
       "      <td>0.751610</td>\n",
       "      <td>-0.120166</td>\n",
       "      <td>-0.420675</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133602</td>\n",
       "      <td>0.020804</td>\n",
       "      <td>0.424312</td>\n",
       "      <td>-0.015989</td>\n",
       "      <td>0.466754</td>\n",
       "      <td>-0.809962</td>\n",
       "      <td>0.657334</td>\n",
       "      <td>-0.043150</td>\n",
       "      <td>-0.046401</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40674</td>\n",
       "      <td>-0.692841</td>\n",
       "      <td>0.166683</td>\n",
       "      <td>1.352646</td>\n",
       "      <td>0.448964</td>\n",
       "      <td>1.288304</td>\n",
       "      <td>-0.926343</td>\n",
       "      <td>0.581101</td>\n",
       "      <td>-0.369026</td>\n",
       "      <td>-0.477145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375500</td>\n",
       "      <td>0.017163</td>\n",
       "      <td>0.210360</td>\n",
       "      <td>-0.260939</td>\n",
       "      <td>-0.019834</td>\n",
       "      <td>0.168770</td>\n",
       "      <td>0.610043</td>\n",
       "      <td>-0.120511</td>\n",
       "      <td>-0.106382</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40929</td>\n",
       "      <td>1.283199</td>\n",
       "      <td>0.153168</td>\n",
       "      <td>0.108935</td>\n",
       "      <td>0.680704</td>\n",
       "      <td>-0.359345</td>\n",
       "      <td>-1.024450</td>\n",
       "      <td>0.192889</td>\n",
       "      <td>-0.227660</td>\n",
       "      <td>0.264378</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.171530</td>\n",
       "      <td>-0.076915</td>\n",
       "      <td>-0.090174</td>\n",
       "      <td>-0.099430</td>\n",
       "      <td>0.437209</td>\n",
       "      <td>0.644058</td>\n",
       "      <td>0.556968</td>\n",
       "      <td>-0.056409</td>\n",
       "      <td>-0.000788</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>42436</td>\n",
       "      <td>-2.481639</td>\n",
       "      <td>-2.439949</td>\n",
       "      <td>0.363642</td>\n",
       "      <td>1.216827</td>\n",
       "      <td>2.572442</td>\n",
       "      <td>-1.264220</td>\n",
       "      <td>-0.443652</td>\n",
       "      <td>0.075853</td>\n",
       "      <td>0.073188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.221691</td>\n",
       "      <td>-0.039426</td>\n",
       "      <td>0.480591</td>\n",
       "      <td>1.779358</td>\n",
       "      <td>-0.756700</td>\n",
       "      <td>-0.161099</td>\n",
       "      <td>0.685617</td>\n",
       "      <td>0.223071</td>\n",
       "      <td>0.139619</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>85326</td>\n",
       "      <td>1.285768</td>\n",
       "      <td>-0.051961</td>\n",
       "      <td>0.174061</td>\n",
       "      <td>-0.254305</td>\n",
       "      <td>-0.434910</td>\n",
       "      <td>-0.701094</td>\n",
       "      <td>-0.133313</td>\n",
       "      <td>-0.022129</td>\n",
       "      <td>0.125110</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.122221</td>\n",
       "      <td>-0.214989</td>\n",
       "      <td>-0.696387</td>\n",
       "      <td>0.072654</td>\n",
       "      <td>0.024097</td>\n",
       "      <td>0.151693</td>\n",
       "      <td>0.853730</td>\n",
       "      <td>-0.097822</td>\n",
       "      <td>-0.012016</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>120996</td>\n",
       "      <td>1.882681</td>\n",
       "      <td>0.296086</td>\n",
       "      <td>-0.152866</td>\n",
       "      <td>4.050789</td>\n",
       "      <td>-0.032225</td>\n",
       "      <td>0.251325</td>\n",
       "      <td>-0.213056</td>\n",
       "      <td>0.061197</td>\n",
       "      <td>-0.190995</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.358383</td>\n",
       "      <td>0.084262</td>\n",
       "      <td>0.527348</td>\n",
       "      <td>0.092488</td>\n",
       "      <td>-0.016210</td>\n",
       "      <td>0.076581</td>\n",
       "      <td>0.139073</td>\n",
       "      <td>-0.001819</td>\n",
       "      <td>-0.048571</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0     430 -1.860258 -0.629859  0.966570  0.844632  0.759983 -1.481173   \n",
       "1   59251  1.331040  0.052830  0.158259 -0.151706 -0.412906 -0.993280   \n",
       "2  148181  0.066427  1.824822 -0.957376  4.224416  1.770814  0.334517   \n",
       "3  148365 -0.625474  1.303970 -0.001461  0.580589  0.372016 -0.411669   \n",
       "4     282 -0.356466  0.725418  1.971749  0.831343  0.369681 -0.107776   \n",
       "5   40674 -0.692841  0.166683  1.352646  0.448964  1.288304 -0.926343   \n",
       "6   40929  1.283199  0.153168  0.108935  0.680704 -0.359345 -1.024450   \n",
       "7   42436 -2.481639 -2.439949  0.363642  1.216827  2.572442 -1.264220   \n",
       "8   85326  1.285768 -0.051961  0.174061 -0.254305 -0.434910 -0.701094   \n",
       "9  120996  1.882681  0.296086 -0.152866  4.050789 -0.032225  0.251325   \n",
       "\n",
       "         V7        V8        V9  ...       V20       V21       V22       V23  \\\n",
       "0 -0.509681  0.540722 -0.733623  ...  0.320450  0.268028  0.125515 -0.225029   \n",
       "1  0.020417 -0.210561  0.272057  ... -0.084019 -0.259684 -0.751655  0.072844   \n",
       "2  0.840841  0.154274 -2.838745  ...  0.166637  0.300908  0.793573 -0.054356   \n",
       "3  0.412633  0.474088 -1.503261  ... -0.216152  0.308786  0.650292 -0.048038   \n",
       "4  0.751610 -0.120166 -0.420675  ... -0.133602  0.020804  0.424312 -0.015989   \n",
       "5  0.581101 -0.369026 -0.477145  ...  0.375500  0.017163  0.210360 -0.260939   \n",
       "6  0.192889 -0.227660  0.264378  ... -0.171530 -0.076915 -0.090174 -0.099430   \n",
       "7 -0.443652  0.075853  0.073188  ... -0.221691 -0.039426  0.480591  1.779358   \n",
       "8 -0.133313 -0.022129  0.125110  ... -0.122221 -0.214989 -0.696387  0.072654   \n",
       "9 -0.213056  0.061197 -0.190995  ... -0.358383  0.084262  0.527348  0.092488   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Amount  \n",
       "0  0.586664 -0.031598  0.570168 -0.043007 -0.223739     0.0  \n",
       "1  0.072357  0.210818  0.870251 -0.089094 -0.000475     0.0  \n",
       "2  0.086829 -0.963660  0.317822  0.160572  0.177744     0.0  \n",
       "3 -0.271956 -1.008158  2.250184 -0.026950  0.163204     0.0  \n",
       "4  0.466754 -0.809962  0.657334 -0.043150 -0.046401     0.0  \n",
       "5 -0.019834  0.168770  0.610043 -0.120511 -0.106382     0.0  \n",
       "6  0.437209  0.644058  0.556968 -0.056409 -0.000788     0.0  \n",
       "7 -0.756700 -0.161099  0.685617  0.223071  0.139619     0.0  \n",
       "8  0.024097  0.151693  0.853730 -0.097822 -0.012016     0.0  \n",
       "9 -0.016210  0.076581  0.139073 -0.001819 -0.048571     0.0  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "newobs = pred.to_dict(orient = 'split')['data']\n",
    "#newobs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[430,\n",
       " -1.8602576921529799,\n",
       " -0.629858920058775,\n",
       " 0.9665704477622901,\n",
       " 0.844632076311716,\n",
       " 0.7599826624018221,\n",
       " -1.4811729034822199,\n",
       " -0.509681452204136,\n",
       " 0.540722084608081,\n",
       " -0.733623387939623,\n",
       " -0.371621504466433,\n",
       " 0.859741162489679,\n",
       " 0.37260884000575,\n",
       " -1.24018476590577,\n",
       " 0.9983913288801859,\n",
       " -0.34638712534557,\n",
       " -0.391678582539051,\n",
       " 0.348289432299279,\n",
       " 0.28212476552471993,\n",
       " 1.1658931653446398,\n",
       " 0.32044962522685,\n",
       " 0.268027795908505,\n",
       " 0.125515236056546,\n",
       " -0.22502853542401702,\n",
       " 0.586664442562558,\n",
       " -0.0315980821137267,\n",
       " 0.570168024306224,\n",
       " -0.0430074855159307,\n",
       " -0.22373947952524498,\n",
       " 0.0]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newobs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instances = [json_format.ParseDict(newobs[0], Value())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Predictions: Python Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[0.0], deployed_model_id='147480793168478208', metadata=None, model_version_id='2', model_resource_name='projects/746038361521/locations/us-central1/models/model_03_03f', explanations=None)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = endpoint.predict(instances = newobs[0:1])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], deployed_model_id='147480793168478208', metadata=None, model_version_id='2', model_resource_name='projects/746038361521/locations/us-central1/models/model_03_03f', explanations=None)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = endpoint.predict(instances = newobs)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(prediction.predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Predictions: REST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{DIR}/request.json','w') as file:\n",
    "    file.write(json.dumps({\"instances\": newobs[0:1]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"predictions\": [\n",
      "    0\n",
      "  ],\n",
      "  \"deployedModelId\": \"147480793168478208\",\n",
      "  \"model\": \"projects/746038361521/locations/us-central1/models/model_03_03f\",\n",
      "  \"modelDisplayName\": \"03_03f\",\n",
      "  \"modelVersionId\": \"2\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl -X POST \\\n",
    "-H \"Authorization: Bearer \"$(gcloud auth application-default print-access-token) \\\n",
    "-H \"Content-Type: application/json; charset=utf-8\" \\\n",
    "-d @{DIR}/request.json \\\n",
    "https://{REGION}-aiplatform.googleapis.com/v1/{endpoint.resource_name}:predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Predictions: gcloud (CLI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-prediction-aiplatform.googleapis.com/]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "!gcloud beta ai endpoints predict {endpoint.name.rsplit('/',1)[-1]} --region={REGION} --json-request={DIR}/request.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Remove Resources\n",
    "see notebook \"99 - Cleanup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undeploying Endpoint model: projects/746038361521/locations/us-central1/endpoints/389096274348998656\n",
      "Undeploy Endpoint model backing LRO: projects/746038361521/locations/us-central1/endpoints/389096274348998656/operations/5264451675107622912\n",
      "Endpoint model undeployed. Resource name: projects/746038361521/locations/us-central1/endpoints/389096274348998656\n",
      "Deleting Endpoint : projects/746038361521/locations/us-central1/endpoints/389096274348998656\n",
      "Endpoint deleted. . Resource name: projects/746038361521/locations/us-central1/endpoints/389096274348998656\n",
      "Deleting Endpoint resource: projects/746038361521/locations/us-central1/endpoints/389096274348998656\n",
      "Delete Endpoint backing LRO: projects/746038361521/locations/us-central1/operations/8689439191722885120\n",
      "Endpoint resource projects/746038361521/locations/us-central1/endpoints/389096274348998656 deleted.\n"
     ]
    }
   ],
   "source": [
    "## DELETE DEPLOYED MODEL AND ENDPOINT \n",
    "endpoint.delete(force=True)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m124"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
