{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started - Vertex AI GenAI Python Client\n",
    "\n",
    "Original source: [vertex-ai-mlops/Applied GenAI/Getting Started - Vertex AI GenAI Python Client.ipynb at main · statmike/vertex-ai-mlops](https://github.com/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Getting%20Started%20-%20Vertex%20AI%20GenAI%20Python%20Client.ipynb)\n",
    "\n",
    "How to get information into (prompts) and out of (responses) of Vertex AI hosted Generative AI Models!\n",
    "\n",
    "Vertex AI has access to hosted [generative AI](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview) models, called foundation models. These can be easily interacted with in the console using [Vertex AI Generative AI Studio](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/generative-ai-studio). This notebook covers interacting with the models with the [`vertexai`](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai) Python package that is include with the Vertex AI SDK [aiplatform](https://cloud.google.com/python/docs/reference/aiplatform/latest).\n",
    "\n",
    "*   Gemini API (Multimodal data, text, code, chat)\n",
    "    *   `vertexai.generative_models`\n",
    "*   PaLM API (Text, chat, embeddings)\n",
    "    *   `vertexai.language_models`\n",
    "*   Codey APIs (Code generation, code chat, code completion)\n",
    "    *   `vertexai.language_models`\n",
    "*   Imagen API (Image generation, image editing, image captioning, visual question answering, and multimodal embedding)\n",
    "    *   `vertexai.vision_models`\n",
    "\n",
    "The current models in GA and in preview can be reviewed in the [documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models) as well as within the [Vertex AI Model Garden](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/model-garden) which also include access to serving and tuning OSS models.\n",
    "\n",
    "Model have names and versions. The [names](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models#model_naming_scheme) are designed show both the purpose and size of the model. For instance, sizes are conveyed with names like `Bison` and `Gecko` while purposes are `text`, `textembedding`, `chat`, `code`, `imagetext`, `imagegeneration` and more. [Versions](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/model-versioning) are either `stable` and available for six months after the release of subsequent version, or `latest` which are incremenatally updated and improved but can give different responses to the same prompt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "\n",
    "\n",
    "## Colab Setup\n",
    "\n",
    "To run this notebook in Colab click <a target=\"_blank\" href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_monitoring/model_monitoring.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a> and run the cells in this section. Otherwise, skip this section.\n",
    "\n",
    "This cell will authenticate to GCP (follow prompts in the popup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PROJECT_ID = 'your-project-id' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demos-vertex-ai\n"
     ]
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "print(PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform'),\n",
    "    ('google.cloud.storage', 'google-cloud-storage')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'demos-vertex-ai'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "SERIES = 'generative-ai'\n",
    "EXPERIMENT = 'getting-started'\n",
    "\n",
    "# Set the BUCKET name for saving work:\n",
    "BUCKET = PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "\n",
    "import vertexai.vision_models # Imagen Models\n",
    "import vertexai.preview.vision_models\n",
    "import vertexai.language_models # PaLM and Codey Models\n",
    "import vertexai.generative_models # for Gemini Models\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.48.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vertexai.init(project = PROJECT_ID, location = REGION)\n",
    "gcs = storage.Client(project = PROJECT_ID)\n",
    "\n",
    "bucket = gcs.lookup_bucket(BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "\n",
    "## Vertex AI Package\n",
    "\n",
    "With the [vertexai](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai) client there are packages for the types of data being interacted with. There is also a higher package for preview models (not yet in GA).\n",
    "\n",
    "> **NOTE:** In can be helpful to review the API Documentation at it's source in GitHub for up to the moment release information: [github/googleapis/python-aiplatform](https://github.com/googleapis/python-aiplatform/tree/main)\n",
    "\n",
    "Gemini Text and Multimodal Models:\n",
    "\n",
    "*   [vertexai.generative\\_models()](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai.generative_models)\n",
    "    *   [vertexai.preview.generative\\_models()](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai.preview.generative_models)\n",
    "\n",
    "Language Models (PaLM and Codey Models):\n",
    "\n",
    "*   [vertexai.language\\_models()](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai.language_models)\n",
    "    *   [vertexai.preview.language\\_models()](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai.preview.language_models)\n",
    "\n",
    "Vision Models (Imagen Models):\n",
    "\n",
    "*   [vertexai.vision\\_models()](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai.vision_models)\n",
    "    *   [vertexai.preview.vision\\_models()](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai.preview.vision_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Gemini Models\n",
    "gemini_text = vertexai.generative_models.GenerativeModel(\"gemini-1.0-pro\")\n",
    "gemini_multimodal = vertexai.generative_models.GenerativeModel(\"gemini-1.0-pro-vision\")\n",
    "\n",
    "# PaLM and Codey Models\n",
    "text_model = vertexai.language_models.TextGenerationModel.from_pretrained('text-bison')\n",
    "chat_model = vertexai.language_models.ChatModel.from_pretrained('chat-bison')\n",
    "textembed_model = vertexai.language_models.TextEmbeddingModel.from_pretrained('textembedding-gecko')\n",
    "codegen_model = vertexai.language_models.CodeGenerationModel.from_pretrained('code-bison')\n",
    "codecomp_model = vertexai.language_models.CodeGenerationModel.from_pretrained('code-gecko')\n",
    "codechat_model = vertexai.language_models.CodeChatModel.from_pretrained('codechat-bison')\n",
    "\n",
    "# Imagen Models\n",
    "imagecap_model = vertexai.vision_models.ImageCaptioningModel.from_pretrained(\"imagetext\")\n",
    "imageqna_model = vertexai.vision_models.ImageQnAModel.from_pretrained(\"imagetext\")\n",
    "imagetext_model = vertexai.vision_models.ImageTextModel.from_pretrained(\"imagetext\")\n",
    "multimodalembed_model = vertexai.vision_models.MultiModalEmbeddingModel.from_pretrained('multimodalembedding')\n",
    "imagen1_model = vertexai.preview.vision_models.ImageGenerationModel.from_pretrained('imagegeneration@002')\n",
    "imagen2_model = vertexai.preview.vision_models.ImageGenerationModel.from_pretrained('imagegeneration@005')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<vertexai.generative_models.GenerativeModel at 0x107eadcc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_multimodal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Resource /projects/demos-vertex-ai/locations/us-central1/publishers/google/models/gemini-1.0-pro-002 is not a valid resource ID.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m aiplatform\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mvertexai\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43maiplatform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/projects/demos-vertex-ai/locations/us-central1/publishers/google/models/gemini-1.0-pro-002\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/cloud/aiplatform/models.py:2909\u001b[0m, in \u001b[0;36mModel.__init__\u001b[0;34m(self, model_name, project, location, credentials, version)\u001b[0m\n\u001b[1;32m   2907\u001b[0m \u001b[38;5;66;03m# Create a versioned model_name, if it exists, for getting the GCA model\u001b[39;00m\n\u001b[1;32m   2908\u001b[0m versioned_model_name \u001b[38;5;241m=\u001b[39m ModelRegistry\u001b[38;5;241m.\u001b[39m_get_versioned_name(model_name, version)\n\u001b[0;32m-> 2909\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gca_resource \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_gca_resource\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mversioned_model_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2911\u001b[0m \u001b[38;5;66;03m# Create ModelRegistry with the unversioned resource name\u001b[39;00m\n\u001b[1;32m   2912\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registry \u001b[38;5;241m=\u001b[39m ModelRegistry(\n\u001b[1;32m   2913\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresource_name,\n\u001b[1;32m   2914\u001b[0m     location\u001b[38;5;241m=\u001b[39mlocation,\n\u001b[1;32m   2915\u001b[0m     project\u001b[38;5;241m=\u001b[39mproject,\n\u001b[1;32m   2916\u001b[0m     credentials\u001b[38;5;241m=\u001b[39mcredentials,\n\u001b[1;32m   2917\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/cloud/aiplatform/base.py:681\u001b[0m, in \u001b[0;36mVertexAiResourceNoun._get_gca_resource\u001b[0;34m(self, resource_name, parent_resource_name_fields)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_gca_resource\u001b[39m(\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    669\u001b[0m     resource_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    670\u001b[0m     parent_resource_name_fields: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    671\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m proto\u001b[38;5;241m.\u001b[39mMessage:\n\u001b[1;32m    672\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns GAPIC service representation of client class resource.\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \n\u001b[1;32m    674\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;124;03m            Should not include project and location.\u001b[39;00m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m     resource_name \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_resource_name\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresource_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresource_noun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resource_noun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_resource_name_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_resource_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m        \u001b[49m\u001b[43mformat_resource_name_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format_resource_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparent_resource_name_fields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparent_resource_name_fields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresource_id_validator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_resource_id_validator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getter_method)(\n\u001b[1;32m    693\u001b[0m         name\u001b[38;5;241m=\u001b[39mresource_name, retry\u001b[38;5;241m=\u001b[39m_DEFAULT_RETRY\n\u001b[1;32m    694\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/cloud/aiplatform/utils/__init__.py:207\u001b[0m, in \u001b[0;36mfull_resource_name\u001b[0;34m(resource_name, resource_noun, parse_resource_name_method, format_resource_name_method, parent_resource_name_fields, project, location, resource_id_validator)\u001b[0m\n\u001b[1;32m    204\u001b[0m user_location \u001b[38;5;241m=\u001b[39m location \u001b[38;5;129;01mor\u001b[39;00m initializer\u001b[38;5;241m.\u001b[39mglobal_config\u001b[38;5;241m.\u001b[39mlocation\n\u001b[1;32m    206\u001b[0m validate_region(user_location)\n\u001b[0;32m--> 207\u001b[0m \u001b[43mresource_id_validator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m format_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_location,\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproject\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_project,\n\u001b[1;32m    212\u001b[0m     convert_camel_case_resource_noun_to_snake_case(resource_noun): resource_name,\n\u001b[1;32m    213\u001b[0m }\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parent_resource_name_fields:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/google/cloud/aiplatform/base.py:532\u001b[0m, in \u001b[0;36mVertexAiResourceNoun._revisioned_resource_id_validator\u001b[0;34m(resource_id)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Some revisioned resource names can have '@' in them\u001b[39;00m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;124;03mto separate the resource ID from the revision ID.\u001b[39;00m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;124;03mThus, they need their own resource id validator.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;124;03m    ValueError: If a `resource_id` doesn't conform to appropriate revision syntax.\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m re\u001b[38;5;241m.\u001b[39mcompile(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw-]+@?[\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw-]+$\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmatch(resource_id):\n\u001b[0;32m--> 532\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResource \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid resource ID.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Resource /projects/demos-vertex-ai/locations/us-central1/publishers/google/models/gemini-1.0-pro-002 is not a valid resource ID."
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "import vertexai\n",
    "\n",
    "aiplatform.Model(\"/projects/demos-vertex-ai/locations/us-central1/publishers/google/models/gemini-1.0-pro-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "* * *\n",
    "\n",
    "## Gemini Models\n",
    "\n",
    "[Reference: Gemini API](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini)\n",
    "\n",
    "### Text Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"What are the starting points for AI?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidates {\n",
       "  content {\n",
       "    role: \"model\"\n",
       "    parts {\n",
       "      text: \"**Historical Foundations:**\\n\\n* **Ancient Greece:** Aristotle\\'s syllogisms (logical reasoning)\\n* **Medieval Europe:** Islamic scholars\\' contributions to algebra and algorithms\\n* **17th Century:** Ren\\303\\251 Descartes\\' analytical geometry, Blaise Pascal\\'s calculating machines\\n* **19th Century:** Charles Babbage\\'s mechanical computer (Analytical Engine)\\n\\n**Modern Era:**\\n\\n* **1950s:** Turing\\'s test of AI intelligence\\n* **1956:** Dartmouth Conference coined the term \\\"artificial intelligence\\\"\\n* **1960s-1970s:** Winter of AI (funding and interest decline)\\n* **1980s-1990s:** Expert systems, machine learning, neural networks\\n* **2000s-Present:** Advancements in deep learning, cloud computing, big data\\n\\n**Theoretical underpinnings:**\\n\\n* **Cognitive Science:** Study of human cognition, providing models for AI development\\n* **Computer Science:** Algorithmic principles, data structures, and computational complexity\\n* **Cybernetics:** Study of feedback and control systems\\n* **Mathematics:** Linear algebra, statistics, probability theory, optimization\\n\\n**Technological Advancements:**\\n\\n* **Computation Power:** Increased computer speed and memory capacity\\n* **Big Data:** Availability of vast amounts of data for training AI models\\n* **Cloud Computing:** Provision of computational resources and storage on demand\\n* **Deep Learning:** Powerful neural networks inspired by human brain architecture\\n* **Natural Language Processing:** AI\\'s ability to understand and generate human language\"\n",
       "    }\n",
       "  }\n",
       "  finish_reason: STOP\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HATE_SPEECH\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.03760863468050957\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.06584469974040985\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.03096751868724823\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.05749328061938286\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HARASSMENT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.09756221622228622\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.04867657274007797\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.05271640419960022\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.03090895712375641\n",
       "  }\n",
       "}\n",
       "usage_metadata {\n",
       "  prompt_token_count: 8\n",
       "  candidates_token_count: 323\n",
       "  total_token_count: 331\n",
       "}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = gemini_text.generate_content(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Historical Foundations:**\n",
       "\n",
       "* **Ancient Greece:** Aristotle's syllogisms (logical reasoning)\n",
       "* **Medieval Europe:** Islamic scholars' contributions to algebra and algorithms\n",
       "* **17th Century:** René Descartes' analytical geometry, Blaise Pascal's calculating machines\n",
       "* **19th Century:** Charles Babbage's mechanical computer (Analytical Engine)\n",
       "\n",
       "**Modern Era:**\n",
       "\n",
       "* **1950s:** Turing's test of AI intelligence\n",
       "* **1956:** Dartmouth Conference coined the term \"artificial intelligence\"\n",
       "* **1960s-1970s:** Winter of AI (funding and interest decline)\n",
       "* **1980s-1990s:** Expert systems, machine learning, neural networks\n",
       "* **2000s-Present:** Advancements in deep learning, cloud computing, big data\n",
       "\n",
       "**Theoretical underpinnings:**\n",
       "\n",
       "* **Cognitive Science:** Study of human cognition, providing models for AI development\n",
       "* **Computer Science:** Algorithmic principles, data structures, and computational complexity\n",
       "* **Cybernetics:** Study of feedback and control systems\n",
       "* **Mathematics:** Linear algebra, statistics, probability theory, optimization\n",
       "\n",
       "**Technological Advancements:**\n",
       "\n",
       "* **Computation Power:** Increased computer speed and memory capacity\n",
       "* **Big Data:** Availability of vast amounts of data for training AI models\n",
       "* **Cloud Computing:** Provision of computational resources and storage on demand\n",
       "* **Deep Learning:** Powerful neural networks inspired by human brain architecture\n",
       "* **Natural Language Processing:** AI's ability to understand and generate human language"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPython.display.Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streaming Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Key\n",
      " Starting Points for Artificial Intelligence (AI)**\n",
      "\n",
      "**1. Data and Information:**\n",
      "* Access to vast amounts of data for training and\n",
      " testing AI models.\n",
      "* Techniques for gathering, cleaning, and preparing data that meets AI requirements.\n",
      "\n",
      "**2. Algorithms and Models:**\n",
      "\n",
      "* Mathematical and statistical models that define the core decision-making processes of AI.\n",
      "* Training methods to optimize models based on available data and expected outcomes.\n",
      "\n",
      "**3. Computing Power:**\n",
      "* High-performance computing resources, such as graphics processing units (\n",
      "GPUs), for efficient model training and inference.\n",
      "* Access to cloud computing platforms that provide scalability and flexibility.\n",
      "\n",
      "**4. Languages and Tools:**\n",
      "* Specialized programming languages (e.g., Python, R) and software libraries for\n",
      " AI development.\n",
      "* Frameworks and platforms for simplifying the development and deployment of AI solutions.\n",
      "\n",
      "**5. Real-World Context:**\n",
      "* Understanding the specific application domain and business goals for which AI is being deployed.\n",
      "* Incorporating domain knowledge and human expertise into AI models.\n",
      "\n",
      "**6. Ethics and Responsibility:**\n",
      "* Ethical considerations related to data privacy, algorithm\n",
      " bias, and impact on society.\n",
      "* Best practices for ensuring responsible and transparent AI development and deployment.\n",
      "\n",
      "**7. Interdisciplinary Collaboration:**\n",
      "* Cooperation between computer scientists, engineers, data analysts, domain experts, and social scientists to combine diverse perspectives and drive innovation.\n",
      "\n",
      "**8. Education and Training:**\n",
      "* Development of educational programs and training materials to foster AI literacy and skills development.\n",
      "* Continuous learning and\n",
      " research to stay abreast of advancements in AI.Statistical ML:** Development of probabilistic models for supervised and unsupervised learning.\n",
      "\n",
      "**Modern AI (Present):**\n",
      "\n",
      "* **Deep Learning:** Advanced neural network architectures with multiple layers, enabling highly accurate results.\n",
      "* **Big Data and Cloud Computing:** Availability of vast amounts of data and powerful computing resources.\n",
      "* **General AI:** Aiming to develop AI systems that can perform a wide range of tasks and reason like humans.\n"
     ]
    }
   ],
   "source": [
    "for response in gemini_text.generate_content(prompt, stream = True):\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async Response\n",
    "\n",
    "The client has built in method for awaitable responses that make it easy to make asynchronous request.\n",
    "\n",
    "> For detailed coverage and examples of asynchronous call to these API's, scaling, error handling, and managing fail over regions check out this notebook in the same folder: [Python Asynchronous API Calls](https://github.com/statmike/vertex-ai-mlops/blob/e7092c381656dc119c5fb1a3dbb78523a4905dd2/Applied%20GenAI/Python%20Asynchronous%20API%20Calls.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Origins and Early Developments:**\n",
       "\n",
       "* **1950s:**\n",
       "    * Dartmouth Summer Research Project on Artificial Intelligence (1956)\n",
       "    * Perceptrons (1957) by Frank Rosenblatt\n",
       "* **1960s:**\n",
       "    * Natural language processing (NLP) and expert systems\n",
       "    * Development of artificial neural networks (ANNs)\n",
       "\n",
       "**Modern Developments:**\n",
       "\n",
       "* **1990s:**\n",
       "    * Introduction of deep neural networks (DNNs)\n",
       "    * Rise of machine learning (ML) and data mining\n",
       "* **2000s:**\n",
       "    * Cloud computing and distributed computing\n",
       "    * Big Data and data analytics\n",
       "    * Emergence of autonomous systems and robotics\n",
       "\n",
       "**Specific Fields and Applications:**\n",
       "\n",
       "* **Computer vision:** Image and video recognition\n",
       "* **Natural language processing:** Language understanding and generation\n",
       "* **Machine learning:** Algorithms that learn from data\n",
       "* **Robotics:** Autonomous movement and control\n",
       "* **Expert systems:** Computer programs that simulate human expertise\n",
       "* **Data mining:** Extraction of knowledge from large datasets\n",
       "\n",
       "**Key Technology Advancements:**\n",
       "\n",
       "* **Hardware advancements:** GPUs, TPUs, and specialized AI chips\n",
       "* **Algorithm improvements:** Deep learning, reinforcement learning, and transfer learning\n",
       "* **Data availability:** Large datasets and open-source repositories\n",
       "* **Computational resources:** Cloud computing and distributed systems"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = await gemini_text.generate_content_async(prompt)\n",
    "IPython.display.Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters For Configuration\n",
    "\n",
    "[Reference: Gemini API](https://cloud.google.com/vertex-ai/docs/generative-ai/model-reference/gemini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidates {\n",
       "  content {\n",
       "    role: \"model\"\n",
       "    parts {\n",
       "      text: \"**Historical Starting Points:**\\n\\n* **1943:** Warren McCulloch and Walter Pitts develop the first artificial neuron model.\\n* **1950:** Alan Turing proposes the Turing Test as a measure of machine intelligence.\\n* **1956:** The Dartmouth Conference establishes the field of artificial intelligence.\\n\\n**Theoretical Foundations:**\\n\\n* **Logic and Reasoning:** Formalizing logical rules and reasoning processes to enable machines to make inferences.\\n* **Machine Learning:** Algorithms that allow machines to learn from data without explicit programming.\\n* **Search and Optimization:** Techniques for finding optimal solutions to complex problems.\\n* **Natural Language Processing:** Understanding and generating human language.\\n* **Computer Vision:** Processing visual data to extract meaningful information.\\n\\n**Technological Advancements:**\\n\\n* **1970s-1980s:** Development of expert systems and rule-based AI.\\n* **1990s:** Emergence of neural networks and deep learning.\\n* **2000s:** Advancements in computing power and data availability.\\n* **2010s:** Widespread adoption of AI in various industries.\\n\\n**Current Trends:**\\n\\n* **Deep Learning:** Neural networks with multiple hidden layers that can learn complex patterns from data.\\n* **Big Data and Cloud Computing:** Access to vast amounts of data and computational resources.\\n* **Edge Computing:** AI algorithms deployed on devices with limited resources.\\n* **Generative AI:** Creating new data or content based on existing patterns.\\n* **Ethical Considerations:** Addressing concerns about bias, privacy, and the potential impact of AI on society.\"\n",
       "    }\n",
       "  }\n",
       "  finish_reason: STOP\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HATE_SPEECH\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.029201289638876915\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.04716186597943306\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.03912164643406868\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.049497053027153015\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HARASSMENT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.08137363195419312\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.039713259786367416\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.07436569780111313\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.039268750697374344\n",
       "  }\n",
       "}\n",
       "usage_metadata {\n",
       "  prompt_token_count: 8\n",
       "  candidates_token_count: 333\n",
       "  total_token_count: 341\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = gemini_text.generate_content(\n",
    "    prompt,\n",
    "    generation_config = vertexai.generative_models.GenerationConfig(\n",
    "        temperature = 0.5,\n",
    "        top_p = .8,\n",
    "        top_k = 25,\n",
    "        candidate_count = 1, \n",
    "        max_output_tokens = 500\n",
    "    )\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Historical Starting Points:**\n",
       "\n",
       "* **1943:** Warren McCulloch and Walter Pitts develop the first artificial neuron model.\n",
       "* **1950:** Alan Turing proposes the Turing Test as a measure of machine intelligence.\n",
       "* **1956:** The Dartmouth Conference establishes the field of artificial intelligence.\n",
       "\n",
       "**Theoretical Foundations:**\n",
       "\n",
       "* **Logic and Reasoning:** Formalizing logical rules and reasoning processes to enable machines to make inferences.\n",
       "* **Machine Learning:** Algorithms that allow machines to learn from data without explicit programming.\n",
       "* **Search and Optimization:** Techniques for finding optimal solutions to complex problems.\n",
       "* **Natural Language Processing:** Understanding and generating human language.\n",
       "* **Computer Vision:** Processing visual data to extract meaningful information.\n",
       "\n",
       "**Technological Advancements:**\n",
       "\n",
       "* **1970s-1980s:** Development of expert systems and rule-based AI.\n",
       "* **1990s:** Emergence of neural networks and deep learning.\n",
       "* **2000s:** Advancements in computing power and data availability.\n",
       "* **2010s:** Widespread adoption of AI in various industries.\n",
       "\n",
       "**Current Trends:**\n",
       "\n",
       "* **Deep Learning:** Neural networks with multiple hidden layers that can learn complex patterns from data.\n",
       "* **Big Data and Cloud Computing:** Access to vast amounts of data and computational resources.\n",
       "* **Edge Computing:** AI algorithms deployed on devices with limited resources.\n",
       "* **Generative AI:** Creating new data or content based on existing patterns.\n",
       "* **Ethical Considerations:** Addressing concerns about bias, privacy, and the potential impact of AI on society."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPython.display.Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grounding With Vertex AI Search & Conversation\n",
    "\n",
    "**in preview, need to load preview model client**\n",
    "\n",
    "Automatically ground prompts in the API call by providing a link to a retrieval source. In this case Vertex AI Search & Conversation data stores can be directly referenced for context retrieval.\n",
    "\n",
    "This section uses a data store created in this repository: [Vertex AI Search](https://github.com/statmike/vertex-ai-mlops/blob/e7092c381656dc119c5fb1a3dbb78523a4905dd2/Applied%20GenAI/Vertex%20AI%20Search/readme.md)\n",
    "\n",
    "*   A data store and search application are created using the official rules manual of baseball\n",
    "\n",
    "Reference: [Grounding Model Responses](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/ground-gemini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gemini_text_preview = vertexai.preview.generative_models.GenerativeModel(\"gemini-pro\")#(\"gemini-1.0-pro\")\n",
    "# from vertexai.preview.generative_models import GenerationConfig, grounding, Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_baseball = \"Is it a homerun when the ball is deflected by a fielder over the outfield fence? Explain.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PaLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The starting points for AI can be traced back to several key moments and developments in the field of computer science and technology:\\n\\n1. **Early Theoretical Foundations**:\\n   - **1940s-1950s**: The birth of AI can be linked to the work of pioneers like Alan Turing, John von Neumann, and Norbert Wiener. Turing\\'s concept of a \"universal computing machine\" and his \"Turing test\" laid the groundwork for the idea of intelligent machines.\\n\\n2. **Dartmouth Summer Research Project (1956)**:\\n   - This workshop, often considered the birthplace of AI'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = text_model.predict(prompt)\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m119"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
