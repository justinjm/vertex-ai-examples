{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started - Vertex AI GenAI Python Client\n",
    "\n",
    "Original source: [vertex-ai-mlops/Applied GenAI/Getting Started - Vertex AI GenAI Python Client.ipynb at main · statmike/vertex-ai-mlops](https://github.com/statmike/vertex-ai-mlops/blob/main/Applied%20GenAI/Getting%20Started%20-%20Vertex%20AI%20GenAI%20Python%20Client.ipynb)\n",
    "\n",
    "How to get information into (prompts) and out of (responses) of Vertex AI hosted Generative AI Models!\n",
    "\n",
    "Vertex AI has access to hosted [generative AI](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/overview) models, called foundation models. These can be easily interacted with in the console using [Vertex AI Generative AI Studio](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/generative-ai-studio). This notebook covers interacting with the models with the [`vertexai`](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai) Python package that is include with the Vertex AI SDK [aiplatform](https://cloud.google.com/python/docs/reference/aiplatform/latest).\n",
    "\n",
    "*   Gemini API (Multimodal data, text, code, chat)\n",
    "    *   `vertexai.generative_models`\n",
    "*   PaLM API (Text, chat, embeddings)\n",
    "    *   `vertexai.language_models`\n",
    "*   Codey APIs (Code generation, code chat, code completion)\n",
    "    *   `vertexai.language_models`\n",
    "*   Imagen API (Image generation, image editing, image captioning, visual question answering, and multimodal embedding)\n",
    "    *   `vertexai.vision_models`\n",
    "\n",
    "The current models in GA and in preview can be reviewed in the [documentation](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models) as well as within the [Vertex AI Model Garden](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/model-garden) which also include access to serving and tuning OSS models.\n",
    "\n",
    "Model have names and versions. The [names](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/models#model_naming_scheme) are designed show both the purpose and size of the model. For instance, sizes are conveyed with names like `Bison` and `Gecko` while purposes are `text`, `textembedding`, `chat`, `code`, `imagetext`, `imagegeneration` and more. [Versions](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/model-versioning) are either `stable` and available for six months after the release of subsequent version, or `latest` which are incremenatally updated and improved but can give different responses to the same prompt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "\n",
    "\n",
    "## Colab Setup\n",
    "\n",
    "To run this notebook in Colab click <a target=\"_blank\" href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/model_monitoring/model_monitoring.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a> and run the cells in this section. Otherwise, skip this section.\n",
    "\n",
    "This cell will authenticate to GCP (follow prompts in the popup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = 'your-project-id' # replace with project ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    !gcloud config set project {PROJECT_ID}\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "demos-vertex-ai\n"
     ]
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "print(PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tuples of (import name, install name, min_version)\n",
    "packages = [\n",
    "    ('google.cloud.aiplatform', 'google-cloud-aiplatform'),\n",
    "    ('google.cloud.storage', 'google-cloud-storage')\n",
    "]\n",
    "\n",
    "import importlib\n",
    "install = False\n",
    "for package in packages:\n",
    "    if not importlib.util.find_spec(package[0]):\n",
    "        print(f'installing package {package[1]}')\n",
    "        install = True\n",
    "        !pip install {package[1]} -U -q --user\n",
    "    elif len(package) == 3:\n",
    "        if importlib.metadata.version(package[0]) < package[2]:\n",
    "            print(f'updating package {package[1]}')\n",
    "            install = True\n",
    "            !pip install {package[1]} -U -q --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if install:\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'demos-vertex-ai'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "REGION = 'us-central1'\n",
    "SERIES = 'generative-ai'\n",
    "EXPERIMENT = 'getting-started'\n",
    "\n",
    "# Set the BUCKET name for saving work:\n",
    "BUCKET = PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "\n",
    "import vertexai.vision_models # Imagen Models\n",
    "import vertexai.preview.vision_models\n",
    "import vertexai.language_models # PaLM and Codey Models\n",
    "import vertexai.generative_models # for Gemini Models\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.44.0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aiplatform.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vertexai.init(project = PROJECT_ID, location = REGION)\n",
    "gcs = storage.Client(project = PROJECT_ID)\n",
    "\n",
    "bucket = gcs.lookup_bucket(BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *\n",
    "\n",
    "## Vertex AI Package\n",
    "\n",
    "With the [vertexai](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai) client there are packages for the types of data being interacted with. There is also a higher package for preview models (not yet in GA).\n",
    "\n",
    "> **NOTE:** In can be helpful to review the API Documentation at it's source in GitHub for up to the moment release information: [github/googleapis/python-aiplatform](https://github.com/googleapis/python-aiplatform/tree/main)\n",
    "\n",
    "Gemini Text and Multimodal Models:\n",
    "\n",
    "*   [vertexai.generative\\_models()](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai.generative_models)\n",
    "    *   [vertexai.preview.generative\\_models()](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai.preview.generative_models)\n",
    "\n",
    "Language Models (PaLM and Codey Models):\n",
    "\n",
    "*   [vertexai.language\\_models()](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai.language_models)\n",
    "    *   [vertexai.preview.language\\_models()](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai.preview.language_models)\n",
    "\n",
    "Vision Models (Imagen Models):\n",
    "\n",
    "*   [vertexai.vision\\_models()](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai.vision_models)\n",
    "    *   [vertexai.preview.vision\\_models()](https://cloud.google.com/python/docs/reference/aiplatform/latest/vertexai.preview.vision_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Gemini Models\n",
    "gemini_text = vertexai.generative_models.GenerativeModel(\"gemini-1.0-pro\")\n",
    "gemini_multimodal = vertexai.generative_models.GenerativeModel(\"gemini-1.0-pro-vision\")\n",
    "\n",
    "# PaLM and Codey Models\n",
    "text_model = vertexai.language_models.TextGenerationModel.from_pretrained('text-bison')\n",
    "chat_model = vertexai.language_models.ChatModel.from_pretrained('chat-bison')\n",
    "textembed_model = vertexai.language_models.TextEmbeddingModel.from_pretrained('textembedding-gecko')\n",
    "codegen_model = vertexai.language_models.CodeGenerationModel.from_pretrained('code-bison')\n",
    "codecomp_model = vertexai.language_models.CodeGenerationModel.from_pretrained('code-gecko')\n",
    "codechat_model = vertexai.language_models.CodeChatModel.from_pretrained('codechat-bison')\n",
    "\n",
    "# Imagen Models\n",
    "imagecap_model = vertexai.vision_models.ImageCaptioningModel.from_pretrained(\"imagetext\")\n",
    "imageqna_model = vertexai.vision_models.ImageQnAModel.from_pretrained(\"imagetext\")\n",
    "imagetext_model = vertexai.vision_models.ImageTextModel.from_pretrained(\"imagetext\")\n",
    "multimodalembed_model = vertexai.vision_models.MultiModalEmbeddingModel.from_pretrained('multimodalembedding')\n",
    "imagen1_model = vertexai.preview.vision_models.ImageGenerationModel.from_pretrained('imagegeneration@002')\n",
    "imagen2_model = vertexai.preview.vision_models.ImageGenerationModel.from_pretrained('imagegeneration@005')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"What are the starting points for AI?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidates {\n",
       "  content {\n",
       "    role: \"model\"\n",
       "    parts {\n",
       "      text: \"* **Formal logic:** The study of reasoning and argumentation, and the development of formal systems to represent and reason about knowledge.\\n* **Cybernetics:** The study of the control and communication systems of animals and machines, and the application of these principles to the design of intelligent systems.\\n* **Information theory:** The study of the quantification, storage, and transmission of information, and the development of mathematical tools for analyzing and designing communication systems.\\n* **Game theory:** The study of strategic decision-making in situations where multiple agents interact, and the development of mathematical models for predicting the outcomes of such games.\\n* **Operations research:** The study of the application of mathematical methods to solve problems in a wide range of fields, including logistics, manufacturing, and finance.\"\n",
       "    }\n",
       "  }\n",
       "  finish_reason: STOP\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HATE_SPEECH\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.028328312560915947\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.0326513797044754\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.057599201798439026\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.04913078621029854\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HARASSMENT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.0960254892706871\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.0271176565438509\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "    probability: NEGLIGIBLE\n",
       "    probability_score: 0.04569203406572342\n",
       "    severity: HARM_SEVERITY_NEGLIGIBLE\n",
       "    severity_score: 0.02753293886780739\n",
       "  }\n",
       "}\n",
       "usage_metadata {\n",
       "  prompt_token_count: 8\n",
       "  candidates_token_count: 156\n",
       "  total_token_count: 164\n",
       "}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = gemini_text.generate_content(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m119",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m119"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
